[
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.1-prepare-environment/",
	"title": "Chuẩn bị môi trường",
	"tags": [],
	"description": "",
	"content": "Lưu ý: Hiện tại AWS sắp ngừng cung cấp Cloud9. Chúng tôi đã đề xuất một số phương pháp thay thế.\nHướng dẫn thiết lập môi trường chạy lab trong tài khoản AWS của bạn Bạn có thể chọn một phương pháp sau để triển khai môi trường\nCloud9 (Đã ngừng hỗ trợ cho tài khoản mới, không khuyến khích) Triển khai VSCode dưới dạng web với EC2 và CloudFront Triển khai VSCode Server trên EC2 và truy cập bằng VSCode trên máy của bạn Triển khai toàn bộ môi trường trên máy của bạn (kết nối có thể bị ảnh hưởng tùy theo Region của bạn) "
},
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Tổng quan về Kubernetes Kubernetes là một nền tảng nguồn mở, có tính cơ động, có thể mở rộng để quản lý các ứng dụng được đóng gói và các service, giúp thuận lợi trong việc cấu hình và tự động hoá việc triển khai ứng dụng. Kubernetes là một hệ sinh thái lớn và phát triển nhanh chóng. Các dịch vụ, sự hỗ trợ và công cụ có sẵn rộng rãi.\nTên gọi Kubernetes có nguồn gốc từ tiếng Hy Lạp, có ý nghĩa là người lái tàu hoặc hoa tiêu. Google mở mã nguồn Kubernetes từ năm 2014. Kubernetes xây dựng dựa trên một thập kỷ rưỡi kinh nghiệm mà Google có được với việc vận hành một khối lượng lớn workload trong thực tế, kết hợp với các ý tưởng và thực tiễn tốt nhất từ cộng đồng.\nBối cảnh lịch sử dẫn đến Kubernetes Chúng ta hãy xem tại sao Kubernetes rất hữu ích bằng cách quay ngược thời gian.\nThời đại triển khai theo cách truyền thống: Ban đầu, các ứng dụng được chạy trên các máy chủ vật lý. Không có cách nào để xác định ranh giới tài nguyên cho các ứng dụng trong máy chủ vật lý và điều này gây ra sự cố phân bổ tài nguyên. Ví dụ, nếu nhiều ứng dụng cùng chạy trên một máy chủ vật lý, có thể có những trường hợp một ứng dụng sẽ chiếm phần lớn tài nguyên hơn và kết quả là các ứng dụng khác sẽ hoạt động kém đi. Một giải pháp cho điều này sẽ là chạy từng ứng dụng trên một máy chủ vật lý khác nhau. Nhưng giải pháp này không tối ưu vì tài nguyên không được sử dụng đúng mức và rất tốn kém cho các tổ chức để có thể duy trì nhiều máy chủ vật lý như vậy.\nThời đại triển khai ảo hóa: Như một giải pháp, ảo hóa đã được giới thiệu. Nó cho phép bạn chạy nhiều Máy ảo (VM) trên CPU của một máy chủ vật lý. Ảo hóa cho phép các ứng dụng được cô lập giữa các VM và cung cấp mức độ bảo mật vì thông tin của một ứng dụng không thể được truy cập tự do bởi một ứng dụng khác.\nẢo hóa cho phép sử dụng tốt hơn các tài nguyên trong một máy chủ vật lý và cho phép khả năng mở rộng tốt hơn vì một ứng dụng có thể được thêm hoặc cập nhật dễ dàng, giảm chi phí phần cứng và hơn thế nữa. Với ảo hóa, bạn có thể có một tập hợp các tài nguyên vật lý dưới dạng một cụm các máy ảo sẵn dùng.\nMỗi VM là một máy tính chạy tất cả các thành phần, bao gồm cả hệ điều hành riêng của nó, bên trên phần cứng được ảo hóa.\nThời đại triển khai Container: Các container tương tự như VM, nhưng chúng có tính cô lập để chia sẻ Hệ điều hành (HĐH) giữa các ứng dụng. Do đó, container được coi là nhẹ (lightweight). Tương tự như VM, một container có hệ thống tệp (filesystem), CPU, bộ nhớ, process space, v.v. Khi chúng được tách rời khỏi cơ sở hạ tầng bên dưới, chúng có thể khả chuyển (portable) trên cloud hoặc các bản phân phối Hệ điều hành.\nCác container đã trở nên phổ biến vì chúng có thêm nhiều lợi ích, chẳng hạn như:\nTạo mới và triển khai ứng dụng Agile: gia tăng tính dễ dàng và hiệu quả của việc tạo các container image so với việc sử dụng VM image. Phát triển, tích hợp và triển khai liên tục: cung cấp khả năng build và triển khai container image thường xuyên và đáng tin cậy với việc rollbacks dễ dàng, nhanh chóng. Phân biệt giữa Dev và Ops: tạo các images của các application container tại thời điểm build/release thay vì thời gian triển khai, do đó phân tách các ứng dụng khỏi hạ tầng. Khả năng quan sát không chỉ hiển thị thông tin và các metric ở mức Hệ điều hành, mà còn cả application health và các tín hiệu khác. Tính nhất quán về môi trường trong suốt quá trình phát triển, testing và trong production: Chạy tương tự trên laptop như trên cloud. Tính khả chuyển trên cloud và các bản phân phối HĐH: Chạy trên Ubuntu, RHEL, CoreOS, on-premises, Google Kubernetes Engine và bất kì nơi nào khác. Quản lý tập trung ứng dụng: Tăng mức độ trừu tượng từ việc chạy một Hệ điều hành trên phần cứng ảo hóa sang chạy một ứng dụng trên một HĐH bằng logical resources. Các micro-services phân tán, elastic: ứng dụng được phân tách thành các phần nhỏ hơn, độc lập và thể được triển khai và quản lý một cách linh hoạt - chứ không phải một app nguyên khối (monolithic). Cô lập các tài nguyên: dự đoán hiệu năng ứng dụng Sử dụng tài nguyên: hiệu quả Tại sao bạn cần Kubernetes và nó có thể làm những gì? Các container là một cách tốt để đóng gói và chạy các ứng dụng của bạn. Trong môi trường production, bạn cần quản lý các container chạy các ứng dụng và đảm bảo rằng không có khoảng thời gian downtime. Ví dụ, nếu một container bị tắt đi, một container khác cần phải khởi động lên. Điều này sẽ dễ dàng hơn nếu được xử lý bởi một hệ thống.\nĐó là cách Kubernetes đến với chúng ta. Kubernetes cung cấp cho bạn một framework để chạy các hệ phân tán một cách mạnh mẽ. Nó đảm nhiệm việc nhân rộng và chuyển đổi dự phòng cho ứng dụng của bạn, cung cấp các mẫu deployment và hơn thế nữa. Ví dụ, Kubernetes có thể dễ dàng quản lý một triển khai canary cho hệ thống của bạn.\nKubernetes cung cấp cho bạn:\nPhát hiện dịch vụ và cân bằng tải: Kubernetes có thể expose một container sử dụng DNS hoặc địa chỉ IP của riêng nó. Nếu lượng traffic truy cập đến một container cao, Kubernetes có thể cân bằng tải và phân phối lưu lượng mạng (network traffic) để việc triển khai được ổn định.\nĐiều phối bộ nhớ: Kubernetes cho phép bạn tự động mount một hệ thống lưu trữ mà bạn chọn, như local storages, public cloud providers, v.v.\nTự động rollouts và rollbacks: Bạn có thể mô tả trạng thái mong muốn cho các container được triển khai dùng Kubernetes và nó có thể thay đổi trạng thái thực tế sang trạng thái mong muốn với tần suất được kiểm soát. Ví dụ, bạn có thể tự động hoá Kubernetes để tạo mới các container cho việc triển khai của bạn, xoá các container hiện có và áp dụng tất cả các resource của chúng vào container mới.\nĐóng gói tự động: Bạn cung cấp cho Kubernetes một cluster gồm các node mà nó có thể sử dụng để chạy các tác vụ được đóng gói (containerized task). Bạn cho Kubernetes biết mỗi container cần bao nhiêu CPU và bộ nhớ (RAM). Kubernetes có thể điều phối các container đến các node để tận dụng tốt nhất các resource của bạn.\nTự phục hồi: Kubernetes khởi động lại các containers bị lỗi, thay thế các container, xoá các container không phản hồi lại cấu hình health check do người dùng xác định và không cho các client biết đến chúng cho đến khi chúng sẵn sàng hoạt động.\nQuản lý cấu hình và bảo mật: Kubernetes cho phép bạn lưu trữ và quản lý các thông tin nhạy cảm như: password, OAuth token và SSH key. Bạn có thể triển khai và cập nhật lại secret và cấu hình ứng dụng mà không cần build lại các container image và không để lộ secret trong cấu hình stack của bạn.\nKubernetes không phải là\u0026hellip; Kubernetes không phải là một hệ thống PaaS (Nền tảng như một Dịch vụ) truyền thống, toàn diện. Do Kubernetes hoạt động ở tầng container chứ không phải ở tầng phần cứng, nó cung cấp một số tính năng thường áp dụng chung cho các dịch vụ PaaS, như triển khai, nhân rộng, cân bằng tải, ghi nhật ký và giám sát. Tuy nhiên, Kubernetes không phải là cấu trúc nguyên khối và các giải pháp mặc định này là tùy chọn và có thể cắm được (pluggable).\nKubernetes KHÔNG thực hiện các việc sau:\nGiới hạn các loại ứng dụng được hỗ trợ. Kubernetes nhằm mục đích hỗ trợ một khối lượng công việc cực kỳ đa dạng, bao gồm cả stateless, stateful và xử lý dữ liệu. Nếu một ứng dụng có thể chạy trong một container, nó sẽ chạy rất tốt trên Kubernetes.\nTriển khai mã nguồn và không build ứng dụng của bạn. Quy trình CI/CD được xác định bởi tổ chức cũng như các yêu cầu kỹ thuật. Không cung cấp các service ở mức ứng dụng, như middleware (ví dụ, các message buses), các framework xử lý dữ liệu (ví dụ, Spark), cơ sở dữ liệu (ví dụ, MySQL), bộ nhớ cache, cũng như hệ thống lưu trữ của cluster (ví dụ, Ceph). Các thành phần như vậy có thể chạy trên Kubernetes và/hoặc có thể được truy cập bởi các ứng dụng chạy trên Kubernetes thông qua các cơ chế di động, chẳng hạn như Open Service Broker.\nBắt buộc các giải pháp ghi lại nhật ký (logging), giám sát (monitoring) hoặc cảnh báo (alerting). Nó cung cấp một số sự tích hợp như proof-of-concept, và cơ chế để thu thập và xuất các số liệu.\nCung cấp, không bắt buộc một cấu hình ngôn ngữ/hệ thống (ví dụ: Jsonnet). Nó cung cấp một API khai báo có thể được targeted bởi các hình thức khai báo tùy ý.\nCung cấp cũng như áp dụng bất kỳ cấu hình toàn diện, bảo trì, quản lý hoặc hệ thống tự phục hồi.\nNgoài ra, Kubernetes cũng không phải một hệ thống điều phối đơn thuần. Trong thực tế, nó loại bỏ sự cần thiết của việc điều phối. Định nghĩa kỹ thuật của điều phối là việc thực thi một quy trình công việc được xác định: đầu tiên làm việc A, sau đó là B rồi sau chót là C. Ngược lại, Kubernetes bao gồm một tập các quy trình kiểm soát độc lập, có thể kết hợp, liên tục điều khiển trạng thái hiện tại theo trạng thái mong muốn đã cho. Nó không phải là vấn đề làm thế nào bạn có thể đi được từ A đến C. Kiểm soát tập trung cũng không bắt buộc. Điều này dẫn đến một hệ thống dễ sử dụng hơn, mạnh mẽ hơn, linh hoạt hơn và có thể mở rộng.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-cluster/",
	"title": "Kiến trúc Cluster",
	"tags": [],
	"description": "",
	"content": "Kiến trúc của một cluster Kubernetes Kiến trúc của một cluster Kubernetes bao gồm các thành phần chính sau:\nMaster Node: Master node quản lý và điều khiển toàn bộ cluster. Các thành phần chính trên master node bao gồm:\nAPI Server: API server là giao diện chính để tương tác với cluster. Tất cả các yêu cầu API từ các thành phần khác đều được xử lý thông qua API server.\nScheduler: Scheduler quyết định nơi chạy các pod mới dựa trên yêu cầu tài nguyên, các ràng buộc và chính sách đã được định nghĩa.\nController Manager: Controller manager chịu trách nhiệm kiểm soát trạng thái của các đối tượng trong cluster (ví dụ: pods, services, replication controllers).\netcd: etcd là một cơ sở dữ liệu phân tán dùng để lưu trữ trạng thái của toàn bộ cluster.\nWorker Node: Các worker node là nơi chứa các container và nơi mà các ứng dụng thực sự chạy. Mỗi worker node có các thành phần sau:\nKubelet: Kubelet là một agent chạy trên mỗi node và quản lý việc chạy các container trên node đó.\nKube-proxy: Kube-proxy quản lý việc giao tiếp mạng giữa các pod và các dịch vụ khác trong cluster.\nContainer Runtime: Container runtime (như Docker hoặc containerd) là phần mềm chịu trách nhiệm quản lý các container.\nPods: Pod là đơn vị nhỏ nhất trong Kubernetes, mỗi pod chứa một hoặc nhiều container. Các container trong cùng một pod chia sẻ cùng một không gian mạng và lưu trữ.\nServices: Services định tuyến yêu cầu đến các pod. Một service đại diện cho một nhóm các pod và cung cấp cách truy cập đồng nhất đến chúng.\nVolumes: Volumes là cách để lưu trữ dữ liệu dạng trên đĩa mà các container có thể chia sẻ và truy cập.\nNamespace: Namespace cho phép chia cluster thành các phần nhỏ hơn, mỗi phần có thể có các tài nguyên riêng biệt và được cấu hình riêng.\nIngress Controller: Ingress controller quản lý việc điều hướng yêu cầu HTTP/HTTPS đến các dịch vụ trong cluster dựa trên các quy tắc cấu hình.\nStorage Classes: Storage classes định nghĩa các loại lưu trữ khác nhau các persistent volume có thể yêu cầu.\nTất cả các thành phần này làm việc cùng nhau để tạo ra một môi trường chạy ứng dụng linh hoạt và mạnh mẽ trên Kubernetes cluster.\n"
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Làm quen với Amazon Elastic Kubernetes Service",
	"tags": [],
	"description": "",
	"content": "Làm quen với Amazon Elastic Kubernetes Service Mục đích Workshop Workshop này thuộc chuỗi workshop về EKS. Tại đây, chúng tôi cung cấp cái nhìn tổng quan, cũng như giúp bạn làm quen với việc triển khai, cấu hình và vận hành các ứng dụng của bạn trên Kubernetes. Với workshop này, chúng tôi hy vọng bạn sẽ hiểu rõ hơn về cách tạo cụm EKS, thực thi các lệnh và triển khai một số công việc đơn giản trên cụm.\nKubernetes Kubernetes là một nền tảng mã nguồn mở, linh hoạt, có khả năng mở rộng, phục vụ việc quản lý các ứng dụng được đóng gói và các dịch vụ liên quan, giúp việc cấu hình và tự động hóa quá trình triển khai ứng dụng trở nên thuận tiện hơn. Được biết đến như một hệ sinh thái lớn và phát triển nhanh chóng, Kubernetes cung cấp sự hỗ trợ rộng rãi qua các dịch vụ và công cụ đa dạng.\nTên Kubernetes bắt nguồn từ tiếng Hy Lạp, nghĩa là người lái tàu hoặc hoa tiêu. Kubernetes được Google công bố mã nguồn vào năm 2014, dựa trên gần một thập kỷ kinh nghiệm quản lý workload lớn trong thực tế của Google, kết hợp với các ý tưởng và best practices từ cộng đồng.\nTại sao bạn cần Kubernetes và nó có thể làm gì? Container là phương tiện hiệu quả để đóng góp và chạy ứng dụng của bạn. Trong môi trường sản xuất, cần có cơ chế quản lý các container một cách hiệu quả, đảm bảo không có downtime. Kubernetes giúp quản lý các hệ thống phân tán mạnh mẽ, tự động hóa việc nhân rộng, cung cấp các mẫu triển khai và nhiều hơn nữa.\nKubernetes mang lại:\nPhát hiện dịch vụ và cân bằng tải Điều phối bộ nhớ Tự động rollouts và rollbacks Đóng gói tự động Tự phục hồi Quản lý cấu hình và bảo mật Amazon Elastic Kubernetes Service (EKS) Amazon Elastic Kubernetes Service (Amazon EKS) là một dịch vụ được quản lý giúp loại bỏ nhu cầu cài đặt, vận hành và bảo trì lớp điều khiển Kubernetes của riêng bạn trên Amazon Web Services (AWS).\nCác tính năng của Amazon EKS Sau đây là các tính năng chính của Amazon EKS:\nXây dựng mạng và xác thực an toàn Amazon EKS tích hợp khối công việc của bạn trên Kubernetes với các dịch vụ mạng và bảo mật của AWS. Nó cũng tích hợp với AWS Identity and Access Management (IAM) để cung cấp xác thực cho các cụm Kubernetes của bạn.\nDễ dàng mở rộng cụm Amazon EKS cho phép bạn dễ dàng chỉnh quy mô các cụm Kubernetes của mình lên và xuống dựa trên nhu cầu của khối lượng công việc của bạn. Amazon EKS hỗ trợ tự động mở rộng Pod theo chiều ngang dựa trên CPU hoặc số liệu tùy chỉnh và tự động mở rộng cụm dựa trên nhu cầu của toàn bộ khối lượng công việc.\nTrải nghiệm Kubernetes được quản lý Bạn có thể thực hiện các thay đổi đối với các cụm Kubernetes của mình bằng eksctl, AWS Management Console, AWS Command Line Interface (AWS CLI), API, kubectl và Terraform.\nTính khả dụng cao Amazon EKS cung cấp tính khả dụng cao cho lớp điều khiển của bạn trên nhiều Vùng khả dụng.\nTích hợp với các dịch vụ AWS Amazon EKS tích hợp với các dịch vụ AWS khác, cung cấp nền tảng toàn diện để triển khai và quản lý các ứng dụng được chứa trong container của bạn. Bạn cũng có thể dễ dàng khắc phục sự cố khối lượng công việc Kubernetes của mình hơn bằng nhiều công cụ quan sát khác nhau.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-cluster/1.1.1-node/",
	"title": "Nodes",
	"tags": [],
	"description": "",
	"content": "Kubernetes chạy các tác vụ của bạn bằng cách đặt các container vào trong Pods để chạy trên Nodes. Một node có thể là máy ảo hoặc máy vật lý, tùy thuộc vào cụm. Mỗi node được quản lý bởi bộ điều khiển và chứa các dịch vụ cần thiết để chạy Pods.\nThông thường, bạn sẽ có nhiều nodes trong một cụm; trong một môi trường học tập hoặc môi trường có hạn chế về tài nguyên, bạn có thể chỉ có một node.\nCác thành phần trên một node bao gồm kubelet, một runtime container, và kube-proxy.\nQuản lý Có hai cách chính để thêm Node vào máy chủ API:\nKubelet trên một node tự đăng ký với Control Plane Bạn (hoặc người dùng khác) tự thêm đối tượng Node Sau khi tạo đối tượng Node hoặc kubelet trên một node tự đăng ký, Control Plane sẽ kiểm tra xem đối tượng Node mới có hợp lệ hay không. Ví dụ: nếu bạn thử tạo Node từ tệp kê khai JSON sau:\n{ \u0026#34;kind\u0026#34;: \u0026#34;Node\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;10.240.79.157\u0026#34;, \u0026#34;labels\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;my-first-k8s-node\u0026#34; } } } Kubernetes tạo một đối tượng Node nội bộ (gọi là \u0026ldquo;đối tượng đại diện\u0026rdquo; (representation)). Kubernetes kiểm tra xem kubelet đã đăng ký với API Server khớp với trường metadata.name của Node hay chưa. Nếu node khỏe mạnh (tức là tất cả các dịch vụ cần thiết đều đang chạy), thì node đó đủ điều kiện để chạy Pod. Nếu không, node đó sẽ bị bỏ qua đối với bất kỳ hoạt động cụm nào cho đến khi node đó khỏe mạnh.\nTính độc nhất của tên node Một Node được xác định bằng tên. Hai Node không thể cùng lúc mang cùng tên. Kubernetes cũng giả định rằng một tài nguyên với một tên gọi là cùng một đối tượng. Trong trường hợp của một Node, ta ngầm định rằng một đối tượng đại diện sử dụng cùng tên sẽ có cùng trạng thái (ví dụ: cài đặt mạng, nội dung đĩa root) và các thuộc tính như nhãn node. Điều này có thể dẫn đến sự không nhất quán nếu một thể hiện được sửa đổi mà không thay đổi tên của nó. Nếu Node cần được thay thế hoặc áp dụng nhiều cập nhật, đối tượng Node hiện có cần được xóa khỏi máy chủ API trước và thêm lại sau khi cập nhật.\nTrạng thái node Trạng thái của một Node chứa các thông tin sau:\nĐịa chỉ\nĐiều kiện/Tình trạng\nDung lượng và khả năng phân bổ\nThông tin\nBạn có thể sử dụng kubectl để xem trạng thái của một Node và các chi tiết khác:\nkubectl describe node \u0026lt;insert-node-name-here\u0026gt; Theo dõi lượng tài nguyên Đối tượng Node theo dõi thông tin về lượng tài nguyên của Node: ví dụ, dung lượng bộ nhớ khả dụng và số lượng CPU. Các Node tự đăng ký sẽ báo cáo dung lượng của chúng trong quá trình đăng ký. Nếu bạn thêm Node theo cách thủ công, thì bạn cần đặt thông tin dung lượng của node khi thêm node đó.\nTrình lên lịch Kubernetes đảm bảo rằng có đủ tài nguyên cho tất cả các Pod trên Node. Trình lên lịch kiểm tra xem tổng các yêu cầu của container trên node có lớn hơn dung lượng của node hay không. Tổng các yêu cầu đó bao gồm tất cả các container do kubelet quản lý, nhưng không bao gồm bất kỳ container nào được khởi chạy trực tiếp bởi thời gian chạy container và cũng không bao gồm bất kỳ quy trình nào chạy bên ngoài tầm kiểm soát của kubelet.\n"
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.2-cluster-creation/2.2.1-eksctl/",
	"title": "Sử dụng eksctl",
	"tags": [],
	"description": "",
	"content": "Xây dựng một cluster cho các bài thực hành lab sử dụng công cụ eksctl. Đây là cách dễ nhất để bắt đầu, và được khuyến nghị cho hầu hết các người học.\nTiện ích eksctl đã được cài đặt sẵn trong Môi trường của bạn, vì vậy chúng ta có thể ngay lập tức tạo ra cluster. Đây là cấu hình sẽ được sử dụng để xây dựng cluster:\napiVersion: eksctl.io/v1alpha5 kind: ClusterConfig availabilityZones: - ${AWS_REGION}a - ${AWS_REGION}b - ${AWS_REGION}c metadata: name: ${EKS_CLUSTER_NAME} region: ${AWS_REGION} version: \u0026#34;1.30\u0026#34; tags: karpenter.sh/discovery: ${EKS_CLUSTER_NAME} created-by: eks-workshop-v2 env: ${EKS_CLUSTER_NAME} iam: withOIDC: true vpc: cidr: 10.42.0.0/16 clusterEndpoints: privateAccess: true publicAccess: true addons: - name: vpc-cni version: 1.16.0 configurationValues: \u0026#39;{\u0026#34;env\u0026#34;:{\u0026#34;ENABLE_PREFIX_DELEGATION\u0026#34;:\u0026#34;true\u0026#34;, \u0026#34;ENABLE_POD_ENI\u0026#34;:\u0026#34;true\u0026#34;, \u0026#34;POD_SECURITY_GROUP_ENFORCING_MODE\u0026#34;:\u0026#34;standard\u0026#34;},\u0026#34;enableNetworkPolicy\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;nodeAgent\u0026#34;: {\u0026#34;enablePolicyEventLogs\u0026#34;: \u0026#34;true\u0026#34;}}\u0026#39; resolveConflicts: overwrite managedNodeGroups: - name: default desiredCapacity: 3 minSize: 3 maxSize: 6 instanceType: m5.large privateNetworking: true releaseVersion: \u0026#34;1.30.0-20240625\u0026#34; updateConfig: maxUnavailablePercentage: 50 labels: workshop-default: \u0026#34;yes\u0026#34; Dựa trên cấu hình này, eksctl sẽ:\nTạo một VPC trên ba AZ Tạo một cluster EKS Tạo một nhà cung cấp IAM OIDC Thêm một nhóm node quản lý có tên là default Cấu hình VPC CNI để sử dụng việc ủy quyền tiền tố Áp dụng tệp cấu hình như sau:\n$ export EKS_CLUSTER_NAME=eks-workshop $ curl -fsSL https://raw.githubusercontent.com/aws-samples/eks-workshop-v2/stable/cluster/eksctl/cluster.yaml | \\ envsubst | eksctl create cluster -f - Thường mất khoảng 20 phút. Khi cluster được tạo, chạy lệnh sau để sử dụng cluster cho các bài thực hành lab:\n$ use-cluster $EKS_CLUSTER_NAME Bước Tiếp Theo Bây giờ cluster đã sẵn sàng, hãy đi đến Bắt đầu module hoặc nhảy tới bất kỳ module nào trong workshop với thanh điều hướng trên cùng. Khi bạn hoàn thành workshop, làm theo các bước dưới đây để dọn dẹp môi trường của bạn.\nDọn Dẹp (các bước sau khi bạn hoàn thành Workshop) Dưới đây là cách bạn sẽ dọn dẹp tài nguyên sau này khi bạn đã sử dụng xong Cluster EKS bạn đã tạo trong các bước trước để hoàn thành các module.\nTrước khi xóa môi trường Cloud9, chúng ta cần dọn dẹp cluster mà chúng ta đã thiết lập trong các bước trước đó.\nĐầu tiên sử dụng delete-environment để đảm bảo rằng ứng dụng mẫu và bất kỳ cơ sở hạ tầng lab còn lại nào được loại bỏ:\n$ delete-environment Tiếp theo, xóa cluster bằng eksctl:\n$ eksctl delete cluster $EKS_CLUSTER_NAME --wait "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.1-prepare-environment/2.1.1-cloud9/",
	"title": "Triển khai môi trường lab trên Cloud9 (Đã ngừng hỗ trợ)",
	"tags": [],
	"description": "",
	"content": "Lưu ý: Hiện tại AWS đã ngừng hỗ trợ Cloud9 cho tài khoản mới. Chúng tôi khuyến khích bạn dùng các giải pháp được nêu ở sau phần này.\nHướng dẫn thiết lập môi trường Cloud9 trong tài khoản AWS của bạn Bước đầu tiên là tạo một IDE với mẫu CloudFormation được cung cấp. Cách đơn giản nhất là mở giao diện CloudFormation theo các đường dẫn dưới đây:\nCác region sau đã được kiểm tra và đảm bảo. Việc chạy các bài workshop tại các vùng địa lý khác có thể không được đảm bảo:\nRegion Cloud9 Link VSCode Link (Preview) us-west2 Launch Launch eu-west-1 Launch Launch ap-southeast-1 Launch Launch Một cách khác là mở CloudShell tại một trong các region trên và chạy các lệnh sau:\n$ wget -q https://raw.githubusercontent.com/aws-samples/eks-workshop-v2/stable/lab/cfn/eks-workshop-ide-cfn.yaml -O eks-workshop-ide-cfn.yaml $ aws cloudformation deploy --stack-name eks-workshop-ide \\ --template-file ./eks-workshop-ide-cfn.yaml \\ --parameter-overrides RepositoryRef=stable \\ --capabilities CAPABILITY_NAMED_IAM Waiting for changeset to be created... Waiting for stack create/update to complete Successfully created/updated stack - eks-workshop-ide CloudFormation Stack sẽ mất khoảng 5 phút để triển khai, và khi hoàn tất, bạn có thể lấy URL cho Cloud9 IDE như sau:\n$ aws cloudformation describe-stacks --stack-name eks-workshop-ide \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`Cloud9Url`].OutputValue\u0026#39; --output text https://us-west-2.console.aws.amazon.com/cloud9/ide/7b05513358534d11afeb7119845c5461?region=us-west-2 Mở URL này trong trình duyệt web để truy cập vào IDE.\nBạn có thể đóng CloudShell ngay bây giờ, tất cả các lệnh tiếp theo sẽ được thực hiện trong phần terminal ở dưới cùng của Cloud9 IDE. AWS CLI đã được cài đặt sẵn và sẽ nhận các thông tin xác thực được gắn với Cloud9 IDE:\n$ aws sts get-caller-identity Bước tiếp theo là tạo một cụm EKS để thực hiện các bài workshop. Nội dung này sẽ được trình bày tại phần 2.2.\n"
},
{
	"uri": "//localhost:1313/vi/3-getting-started/1-sample-application/",
	"title": "Ứng dụng mẫu",
	"tags": [],
	"description": "",
	"content": "Chào mừng bạn đến với lab thực hành đầu tiên trong workshop EKS. Mục tiêu của bài tập này là làm quen với ứng dụng mẫu mà chúng ta sẽ sử dụng cho nhiều bài lab tiếp theo và qua đó đề cập đến một số khái niệm cơ bản liên quan đến triển khai workloads trên EKS. Chúng ta sẽ tìm hiểu kiến trúc của ứng dụng và triển khai các thành phần vào cluster EKS của chúng ta.\nHãy triển khai workload đầu tiên của bạn vào cluster EKS trong môi trường lab của bạn và khám phá !\nTrước khi chúng ta bắt đầu, chúng ta cần chạy lệnh sau để chuẩn bị môi trường Cloud9 và cluster EKS của chúng ta:\n$ prepare-environment introduction/getting-started Lệnh này làm gì? Đối với lab này, nó sao chép kho Git Workshop EKS vào môi trường Cloud9 để các tệp Kubernetes Manifest cần thiết tồn tại trên hệ thống tệp.\nBạn sẽ thấy trong các lab tiếp theo, chúng ta cũng sẽ chạy lệnh này, nơi nó sẽ thực hiện hai chức năng quan trọng bổ sung:\nThiết lập lại cluster EKS về trạng thái ban đầu của nó Cài đặt các thành phần bổ sung cần thiết vào cluster cho bài lab tiếp theo Sử Dụng Ứng Dụng Mẫu Trong AWS và Kubernetes Đa số các lab trong workshop này sử dụng một ứng dụng mẫu chung để cung cấp các thành phần container thực tế mà chúng ta có thể làm việc trong suốt các bài tập. Ứng dụng mẫu mô hình một ứng dụng cửa hàng web đơn giản, nơi khách hàng có thể duyệt một danh mục, thêm các mặt hàng vào giỏ hàng của họ và hoàn tất một đơn hàng thông qua quá trình thanh toán. s Ứng dụng có một số thành phần và phụ thuộc:\nThành Phần Mô Tả UI Cung cấp giao diện người dùng phía trước và tổng hợp cuộc gọi API đến các dịch vụ khác nhau. Catalog API cho việc liệt kê và chi tiết sản phẩm Cart API cho giỏ hàng mua sắm của khách hàng Checkout API để điều phối quá trình thanh toán Orders API để nhận và xử lý đơn hàng của khách hàng Static assets Cung cấp tài nguyên tĩnh như hình ảnh liên quan đến danh mục sản phẩm Ban đầu, chúng ta sẽ triển khai ứng dụng một cách độc lập trong cụm Amazon EKS, mà không sử dụng bất kỳ dịch vụ AWS nào như cân bằng tải hoặc cơ sở dữ liệu được quản lý. Trong suốt các lab, chúng ta sẽ tận dụng các tính năng khác nhau của EKS để tận dụng các dịch vụ và tính năng của AWS rộng lớn hơn cho cửa hàng bán lẻ của chúng ta.\nBạn có thể tìm mã nguồn đầy đủ cho ứng dụng mẫu trên GitHub.\n"
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/",
	"title": "Các Bước Chuẩn Bị",
	"tags": [],
	"description": "",
	"content": "Trước khi làm các bài thực hành của bộ workshop EKS, vui lòng thực hiện ba bước sau đây:\nChuẩn bị môi trường\nTạo và chuẩn bị cho hệ thống của bạn kết nối được với AWS.\nChuẩn bị IDE và cây thư mục mã nguồn.\nTạo cụm EKS\nTạo cụm EKS để triển khai các khối công việcs.\nTạo bằng CloudFormation hoặc Terraform\nTìm hiểu cấu trúc lab\n"
},
{
	"uri": "//localhost:1313/vi/3-getting-started/2-lab-components/",
	"title": "Các thành phần",
	"tags": [],
	"description": "",
	"content": "Các thành phần Trước khi một công việc có thể được triển khai lên một bản phân phối Kubernetes như EKS, nó trước tiên phải được đóng gói như một hình ảnh container và xuất bản vào một registry container. Các chủ đề cơ bản về container như này không được bao gồm trong phần workshop này, và ứng dụng mẫu đã có các hình ảnh container sẵn có trong Amazon Elastic Container Registry cho các lab mà chúng ta sẽ hoàn thành hôm nay.\nBảng dưới đây cung cấp các liên kết đến kho chứa công cộng ECR cho mỗi thành phần, cũng như Dockerfile đã được sử dụng để xây dựng từng thành phần.\nComponent ECR Public repository Dockerfile UI Repository Dockerfile Catalog Repository Dockerfile Shopping cart Repository Dockerfile Checkout Repository Dockerfile Orders Repository Dockerfile Assets Repository Dockerfile "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.2-containerruntimes/",
	"title": "Container Runtime",
	"tags": [],
	"description": "",
	"content": "Phần này sẽ cung cấp một cái nhìn tổng quan về container runtime.\nContainer runtime là gì ? Container runtime là phần mềm nền tảng để container hoạt động trong hệ thống máy chủ. Container runtime chịu trách nhiệm cho mọi thứ, từ việc kéo các container image từ registry và quản lý vòng đời của chúng, đến chạy container trên hệ thống của bạn.\nChức năng và vai trò Việc hiểu các chức năng và vai trò cốt lõi rất quan trọng đối với việc đánh giá cách Container Runtime hỗ trợ việc thực hiện và quản lý container một cách liền mạch. Nhìn chung, một container runtime thực hiện những việc sau:\nThực thi container Container runtime chủ yếu thực thi container thông qua một quy trình nhiều bước. Bước đầu tiên, quy trình này bắt đầu bằng cách tạo container và môi trường của nó dựa trên một container image chứa ứng dụng cùng các phần phụ thuộc. Sau khi tạo, runtime chạy các container, khởi động ứng dụng và đảm bảo chức năng phù hợp. Ngoài ra, runtime quản lý vòng đời của container, bao gồm theo dõi tình trạng, khởi động lại nếu chúng bị lỗi và dọn dẹp tài nguyên sau khi các container không còn được sử dụng nữa.\nTương tác với hệ điều hành chủ Các container runtime tương tác chặt chẽ với hệ điều hành chủ. Chúng tận dụng nhiều tính năng khác nhau của hệ điều hành, như namespace và cgroup, để cô lập và quản lý tài nguyên cho từng container. Sự cô lập này đảm bảo rằng các quy trình bên trong container không thể làm gián đoạn máy chủ hoặc các container khác, duy trì môi trường an toàn và ổn định.\nCấp phát và quản lý tài nguyên Các container runtime là một phần thiết yếu trong quản lý tài nguyên vì chúng phân bổ và điều chỉnh CPU, bộ nhớ và quá trình I/O cho từng container để ngăn chặn tình trạng độc chiếm tài nguyên, đặc biệt là trong môi trường multi-tenant (nhiều bên sử dụng). Cách container runtime xử lý trơn tru quá trình chạy, vòng đời và tương tác giữa container và hệ điều hành máy chủ là chìa khóa để container hóa trở thành một phần quan trọng trong bối cảnh phát triển phần mềm ngày nay.\nContainer Runtime - Bậc thấp và Bậc cao Khi nhắc đến container runtime, người ta có thể nghĩ đến một danh sách các ví dụ: runc, lxc, lmctfy, Docker (containerd), rkt, cri-o. Mỗi loại này được xây dựng cho các tình huống khác nhau và triển khai các tính năng khác nhau. Một số loại, như containerd và cri-o, thực sự sử dụng runc để chạy container nhưng triển khai quản lý image và API ở trên. Bạn có thể coi các tính năng này – bao gồm vận chuyển image, quản lý image, giải nén image và API – là các tính năng bậc cao so với triển khai bậc thấp của runc.\nVới điều đó trong đầu, bạn có thể thấy rằng không gian container runtime khá phức tạp. Mỗi runtime bao gồm các phần khác nhau trên phổ bậc thấp-cao. Sau đây là một sơ đồ rất chủ quan:\nDo đó, để phù hợp thực tế, các container runtime thật sự chỉ tập trung vào việc chạy container thường được gọi là \u0026ldquo;container runtime bậc thấp\u0026rdquo;. Runtime hỗ trợ nhiều tính năng bậc cao hơn, như quản lý image và API gRPC/Web, thường được gọi là \u0026ldquo;công cụ container bậc cao\u0026rdquo;, \u0026ldquo;container runtime bậc cao\u0026rdquo; hoặc thường chỉ là \u0026ldquo;container runtime\u0026rdquo;. Phần này sẽ gọi chúng là \u0026ldquo;container runtime bậc cao\u0026rdquo;. Điều quan trọng cần lưu ý là runtime bậc thấp và runtime bậc cao về cơ bản là những thứ khác nhau giải quyết các vấn đề khác nhau.\nThông thường, các nhà phát triển muốn chạy ứng dụng trong container sẽ cần nhiều hơn các tính năng runtime bậc thấp cung cấp. Họ cần API và các tính năng xoay quanh việc định dạng, quản lý và chia sẻ các image. Các tính năng này được cung cấp bởi runtime bậc cao. Runtime bậc thấp không cung cấp đủ tính năng cho mục đích sử dụng hàng ngày này. Do đó, những người duy nhất thực sự sử dụng runtime bậc thấp sẽ chỉ có các nhà phát triển triển khai runtime bậc cao hơn và các công cụ cho container.\nCác nhà phát triển triển khai runtime bậc thấp sẽ nói rằng các runtime bậc cao hơn như containerd và cri-o không thực sự là container runtime, vì theo họ, chúng \u0026ldquo;ủy thác\u0026rdquo; việc triển khai chạy container cho runc. Tuy nhiên, từ góc độ người dùng, chúng là như một thành phần duy nhất cung cấp khả năng chạy container.\nContainer runtimes trên Kubernetes Kubernetes runtime là container runtime bậc cao hỗ trợ Giao diện container runtime (CRI). CRI được giới thiệu trong Kubernetes 1.5 và hoạt động như một cầu nối giữa kubelet và container runtime. Container runtime bậc cao muốn tích hợp với Kubernetes được kỳ vọng sẽ triển khai CRI. Runtime được kỳ vọng sẽ xử lý việc quản lý image và hỗ trợ các pod Kubernetes, cũng như quản lý các container riêng lẻ và do đó, được coi là runtime bậc cao theo phân loại ở trên.\nĐể hiểu thêm về CRI, chúng ta nên xem lại kiến ​​trúc Kubernetes tổng thể một lần nữa. Kubelet là một tác nhân nằm trên mỗi nút worker trong cụm Kubernetes. Kubelet chịu trách nhiệm quản lý khối lượng công việc container cho nút của nó. Khi thực sự chạy khối lượng công việc, kubelet sử dụng CRI để giao tiếp với container runtime đang chạy trên cùng một nút đó. Theo cách này, CRI chỉ đơn giản là một lớp trừu tượng hoặc API cho phép bạn chuyển đổi các triển khai container runtime thay vì tích hợp chúng vào kubelet.\nDưới đây là một số runtime dùng được trên Kubernetes:\nDocker Docker là một trong những container runtime nguồn mở đầu tiên. Nó được phát triển bởi công ty nền tảng dịch vụ dotCloud và được sử dụng để chạy các ứng dụng web của người dùng trong container.\nDocker là container runtime kết hợp xây dựng, đóng gói, chia sẻ và chạy container. Docker có kiến ​​trúc máy khách/máy chủ và ban đầu được xây dựng dưới dạng daemon nguyên khối, dockerd và ứng dụng máy khách docker. Daemon cung cấp hầu hết logic để xây dựng container, quản lý image và chạy container, cùng với API. Máy khách dòng lệnh có thể được chạy để gửi lệnh và lấy thông tin từ daemon.\nDocker ban đầu triển khai cả tính năng runtime bậc cao và bậc thấp, song các phần đó đã được chia thành các dự án riêng biệt là runc và containerd. Docker hiện bao gồm daemon dockerd và daemon docker-containerd cùng với `docker-runc`. `docker-`containerd và docker-runc chỉ là các phiên bản được Docker đóng gói của containerd và runc nguyên bản.\ndockerd cung cấp các tính năng như xây dựng image và dockerd sử dụng docker-containerd để cung cấp các tính năng như quản lý image và chạy container. Ví dụ, bước xây dựng của Docker thực chất chỉ là một số logic diễn giải Dockerfile, chạy các lệnh cần thiết trong container bằng containerd và lưu hệ thống tệp container kết quả dưới dạng image.\ncontainerd containerd là một runtime cấp cao được tách ra từ Docker. Giống như runc, được tách ra thành phần runtime cấp thấp, containerd được tách ra thành phần runtime cấp cao của Docker. containerd triển khai việc tải xuống image, quản lý chúng và chạy các container từ image. Khi cần chạy một container, nó sẽ giải nén image thành một gói OCI runtime và shell ra runc để chạy nó.\ncontainerd cũng cung cấp một API và ứng dụng client dùng để tương tác với nó. CLI của containerd là ctr.\nctr có thể được sử dụng để yêu cầu containerd kéo một container image:\nsudo ctr images pull docker.io/library/redis:latest Liệt kê các image của bạn:\nsudo ctr images list Khởi tạo container từ image:\nsudo ctr container create docker.io/library/redis:latest redis Liệt kê các container đang chạy\nsudo ctr container list Dừng container:\nsudo ctr container delete redis Các lệnh này tương tự như cách người dùng tương tác với Docker. Tuy nhiên, trái ngược với Docker, containerd chỉ tập trung vào việc chạy container, do đó nó không cung cấp cơ chế để xây dựng container. Docker tập trung vào các trường hợp sử dụng của người dùng cuối và nhà phát triển, trong khi containerd tập trung vào các trường hợp sử dụng cho vận hành, chẳng hạn như chạy container trên máy chủ. Các tác vụ như xây dựng container image được giao cho các công cụ khác.\ncri-o cri-o là một CRI runtime nhẹ được tạo ra như một runtime bậc cao dành riêng cho Kubernetes. Nó hỗ trợ quản lý các image tương thích với OCI và kéo từ bất kỳ OCI image registry nào tương thích. Nó hỗ trợ runc và Clear Containers như các runtime bậc thấp. Về mặt lý thuyết, nó hỗ trợ các runtime bậc thấp tương thích với OCI khác, nhưng dựa vào khả năng tương thích với giao diện dòng lệnh runc OCI, vì vậy trên thực tế nó không linh hoạt bằng API shim của containerd.\ncri-o’s endpoint is at /var/run/crio/crio.sock by default so you can configure crictl like so. cat \u0026lt;\u0026lt;EOF | sudo tee /etc/crictl.yaml runtime-endpoint: unix:///var/run/crio/crio.sock EOF Tương tác với CRI Ta có thể tương tác trực tiếp với CRI runtime bằng công cụ crictl. crictl cho phép gửi tin nhắn gRPC đến CRI runtime trực tiếp từ dòng lệnh. Chúng ta có thể sử dụng công cụ này để gỡ lỗi và kiểm tra các bản triển khai CRI mà không cần khởi động cụm Kubernetes hoàn chỉnh. Bạn có thể tải xuống tệp nhị phân crictl từ trang phát hành cri-tools trên GitHub.\nBạn có thể định cấu hình crictl bằng cách tạo tệp cấu hình trong /etc/crictl.yaml. Tại đây, bạn nên chỉ định gRPC endpoint của runtime là tệp socket Unix (unix:///path/to/file) hoặc TCP endpoint (tcp://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;). Chúng ta sẽ sử dụng containerd cho ví dụ này:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/crictl.yaml runtime-endpoint: unix:///run/`containerd`/`containerd`.sock EOF Hoặc bạn có thể xác định cụ thể runtime endpoint cho mỗi lần chạy lệnh:\ncrictl --runtime-endpoint unix:///run/`containerd`/`containerd`.sock … Let’s run a pod with a single container with crictl. First you would tell the runtime to pull the nginx image you need since you can’t start a container without the image stored locally.\nsudo crictl pull nginx Hãy chạy một pod với một container duy nhất bằng crictl. Đầu tiên, bạn sẽ yêu cầu runtime kéo image nginx mà bạn cần vì bạn không thể khởi động một container mà không có image được lưu trữ cục bộ.\ncat \u0026lt;\u0026lt;EOF | tee sandbox.json { \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;nginx-sandbox\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;attempt\u0026#34;: 1, \u0026#34;uid\u0026#34;: \u0026#34;hdishd83djaidwnduwk28bcsb\u0026#34; }, \u0026#34;linux\u0026#34;: { }, \u0026#34;log_directory\u0026#34;: \u0026#34;/tmp\u0026#34; } EOF Sau đó tạo sandbox cho pod. Chúng ta sẽ lưu ID của sandbox vào biến SANDBOX_ID.\nSANDBOX_ID=$(sudo crictl runp --runtime runsc sandbox.json) Next we will create a container creation request in a JSON file. cat \u0026lt;\u0026lt;EOF | tee container.json { \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;nginx\u0026#34; }, \u0026#34;image\u0026#34;:{ \u0026#34;image\u0026#34;: \u0026#34;nginx\u0026#34; }, \u0026#34;log_path\u0026#34;:\u0026#34;nginx.0.log\u0026#34;, \u0026#34;linux\u0026#34;: { } } EOF Tiếp đến chúng ta có thể tạo và khởi động container bên trong Pod mà chúng ta đã tạo trước đó.\nCONTAINER_ID=$(sudo crictl create ${SANDBOX_ID} container.json sandbox.json) sudo crictl start ${CONTAINER_ID} Dùng lệnh sau để xem thông tin pod đang chạy:\nsudo crictl inspectp ${SANDBOX_ID} … và container đang chạy:\nsudo crictl inspect ${CONTAINER_ID} Dọn dẹp bằng cách dừng và xóa container:\nsudo crictl stop ${CONTAINER_ID} sudo crictl rm ${CONTAINER_ID} Và cuối cùng là dừng và xóa pod:\nsudo crictl stopp ${SANDBOX_ID} sudo crictl rmp ${SANDBOX_ID} Tham khảo https://www.wiz.io/academy/container-runtimes https://www.ianlewis.org/en/container-runtimes-part-1-introduction-container-r https://www.ianlewis.org/en/container-runtimes-part-4-kubernetes-container-run "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-cluster/1.1.2-communitcation/",
	"title": "Giao tiếp giữa các Node và Control Plane",
	"tags": [],
	"description": "",
	"content": "Phần này liệt kê các đường giao tiếp giữa máy chủ API và cụm Kubernetes. Mục đích là để cho phép người dùng tùy chỉnh cài đặt của mình nhằm tăng cường cấu hình mạng, từ đó cụm có thể được vận hành trên một mạng không tin cậy (hoặc trên các IP công cộng hoàn toàn trên nhà cung cấp đám mây).\nTừ Node đến Control Plane Kubernetes áp dụng mô hình API \u0026ldquo;hub-and-spoke\u0026rdquo;. Tất cả việc sử dụng API từ các node (hoặc các pod được chúng chạy) đều kết thúc tại máy chủ API. Không có thành phần nào khác của control plane được thiết kế để tiết lộ dịch vụ từ xa. Máy chủ API được cấu hình để lắng nghe các kết nối từ xa trên cổng HTTPS an toàn (thông thường là 443) với một hoặc nhiều hình thức xác thực khách hàng được kích hoạt. Một hoặc nhiều hình thức ủy quyền nên được kích hoạt, đặc biệt nếu cho phép yêu cầu ẩn danh hoặc token tài khoản dịch vụ.\nCác node nên được cung cấp chứng chỉ root công khai cho cụm để chúng có thể kết nối một cách an toàn đến máy chủ API cùng với các thông tin đăng nhập khách hàng hợp lệ. Một cách tiếp cận tốt là thông tin đăng nhập khách hàng được cung cấp cho kubelet dưới dạng một chứng chỉ khách hàng. Xem khoản bootstrap TLS kubelet để tự động cung cấp chứng chỉ khách hàng cho kubelet.\nCác pod muốn kết nối đến máy chủ API có thể làm như vậy một cách an toàn bằng cách tận dụng một tài khoản dịch vụ sao cho Kubernetes sẽ tự động tiêm chứng chỉ root công khai và token bearer hợp lệ vào pod khi nó được khởi tạo. Dịch vụ Kubernetes (trong namespace mặc định) được cấu hình với một địa chỉ IP ảo được chuyển hướng (thông qua kube-proxy) đến điểm cuối HTTPS trên máy chủ API.\nCác thành phần của control plane cũng giao tiếp với máy chủ API qua cổng an toàn.\nKết quả là, chế độ vận hành mặc định cho các kết nối từ các node và pod chạy trên các node đến control plane được bảo mật theo mặc định và có thể vận hành trên các mạng không tin cậy và/hoặc công cộng.\nTừ Control Plane đến Node Có hai con đường giao tiếp chính từ control plane (máy chủ API) đến các node. Đầu tiên là từ máy chủ API đến quy trình kubelet chạy trên mỗi node trong cụm. Thứ hai là từ máy chủ API đến bất kỳ node, pod, hoặc dịch vụ nào thông qua chức năng proxy của máy chủ API. Máy chủ API đến kubelet Các kết nối từ máy chủ API đến kubelet được sử dụng cho:\nLấy log cho các pod. Đính kèm (thường qua kubectl) vào các pod đang chạy. Cung cấp chức năng chuyển tiếp cổng của kubelet. Những kết nối này kết thúc tại điểm cuối HTTPS của kubelet. Theo mặc định, máy chủ API không xác minh chứng chỉ phục vụ của kubelet, điều này khiến kết nối dễ bị tấn công man-in-the-middle và không an toàn để vận hành trên các mạng không tin cậy và/hoặc công cộng. Để xác minh kết nối này, sử dụng cờ \u0026ndash;kubelet-certificate-authority để cung cấp cho máy chủ API một gói chứng chỉ root để sử dụng để xác minh chứng chỉ phục vụ của kubelet. Nếu điều đó không khả thi, sử dụng SSH Tunnel giữa máy chủ API và kubelet nếu cần thiết để tránh kết nối qua một mạng không tin cậy hoặc công cộng. Cuối cùng, xác thực và/hoặc ủy quyền kubelet nên được kích hoạt để bảo mật API của kubelet. Máy chủ API đến Node, Pod, và Dịch vụ Các kết nối từ máy chủ API đến một node, pod, hoặc dịch vụ mặc định là các kết nối HTTP đơn giản và do đó không được xác thực hoặc mã hóa. Chúng có thể được vận hành qua một kết nối HTTPS an toàn bằng cách thêm tiền tố https: vào tên node, pod, hoặc dịch vụ trong URL API, nhưng chúng sẽ không xác minh chứng chỉ được cung cấp bởi điểm cuối HTTPS cũng như không cung cấp thông tin đăng nhập khách hàng. Vì vậy, mặc dù kết nối sẽ được mã hóa, nó không cung cấp bất kỳ bảo đảm nào về tính toàn vẹn. Những kết nối này hiện không an toàn để vận hành trên các mạng không tin cậy hoặc công cộng. "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.2-cluster-creation/2.2.2-terraform/",
	"title": "Sử dụng Terraform",
	"tags": [],
	"description": "",
	"content": "Xây dựng một cụm cho các bài thực hành Lab sử dụng Hashicorp Terraform. Đây nhằm mục đích phục vụ cho những người học đã quen với việc làm việc với hạ tầng mã nguồn mở của Terraform.\nCLI terraform đã được cài đặt sẵn trong Môi trường Amazon Cloud9 của bạn, vì vậy chúng ta có thể ngay lập tức tạo ra cụm. Hãy xem qua các tập tin cấu hình Terraform chính sẽ được sử dụng để xây dựng cụm và hạ tầng hỗ trợ của nó.\nHiểu các tập tin cấu hình Terraform Tập tin providers.tf cấu hình các nhà cung cấp Terraform mà sẽ cần để xây dựng hạ tầng. Trong trường hợp này, của chúng ta sử dụng các nhà cung cấp aws, kubernetes và helm:\nprovider \u0026#34;aws\u0026#34; {\rdefault_tags {\rtags = local.tags\r}\r}\rterraform {\rrequired_providers {\raws = {\rsource = \u0026#34;hashicorp/aws\u0026#34;\rversion = \u0026#34;\u0026gt;= 4.67.0\u0026#34;\r}\r}\rrequired_version = \u0026#34;\u0026gt;= 1.4.2\u0026#34;\r} Tập tin main.tf thiết lập một số nguồn dữ liệu Terraform để chúng ta có thể lấy thông tin tài khoản AWS và region hiện đang được sử dụng, cũng như một số thẻ mặc định:\nlocals {\rtags = {\rcreated-by = \u0026#34;eks-workshop-v2\u0026#34;\renv = var.cluster_name\r}\r} Cấu hình vpc.tf sẽ đảm bảo hạ tầng VPC của chúng ta được tạo ra:\nlocals {\rprivate_subnets = [for k, v in local.azs : cidrsubnet(var.vpc_cidr, 3, k + 3)]\rpublic_subnets = [for k, v in local.azs : cidrsubnet(var.vpc_cidr, 3, k)]\razs = slice(data.aws_availability_zones.available.names, 0, 3)\r}\rdata \u0026#34;aws_availability_zones\u0026#34; \u0026#34;available\u0026#34; {\rstate = \u0026#34;available\u0026#34;\r}\rmodule \u0026#34;vpc\u0026#34; {\rsource = \u0026#34;terraform-aws-modules/vpc/aws\u0026#34;\rversion = \u0026#34;~\u0026gt; 5.1\u0026#34;\rname = var.cluster_name\rcidr = var.vpc_cidr\razs = local.azs\rpublic_subnets = local.public_subnets\rprivate_subnets = local.private_subnets\rpublic_subnet_suffix = \u0026#34;SubnetPublic\u0026#34;\rprivate_subnet_suffix = \u0026#34;SubnetPrivate\u0026#34;\renable_nat_gateway = true\rcreate_igw = true\renable_dns_hostnames = true\rsingle_nat_gateway = true\r# Manage so we can name\rmanage_default_network_acl = true\rdefault_network_acl_tags = { Name = \u0026#34;${var.cluster_name}-default\u0026#34; }\rmanage_default_route_table = true\rdefault_route_table_tags = { Name = \u0026#34;${var.cluster_name}-default\u0026#34; }\rmanage_default_security_group = true\rdefault_security_group_tags = { Name = \u0026#34;${var.cluster_name}-default\u0026#34; }\rpublic_subnet_tags = merge(local.tags, {\r\u0026#34;kubernetes.io/role/elb\u0026#34; = \u0026#34;1\u0026#34;\r})\rprivate_subnet_tags = merge(local.tags, {\r\u0026#34;karpenter.sh/discovery\u0026#34; = var.cluster_name\r\u0026#34;kubernetes.io/role/internal-elb\u0026#34; = \u0026#34;1\u0026#34;\r})\rtags = local.tags\r} Cuối cùng, tập tin eks.tf chỉ định cấu hình cụm EKS của chúng tôi, bao gồm một Nhóm Node Quản lý:\nmodule \u0026#34;eks\u0026#34; {\rsource = \u0026#34;terraform-aws-modules/eks/aws\u0026#34;\rversion = \u0026#34;~\u0026gt; 20.0\u0026#34;\rcluster_name = var.cluster_name\rcluster_version = var.cluster_version\rcluster_endpoint_public_access = true\renable_cluster_creator_admin_permissions = true\rcluster_addons = {\rvpc-cni = {\rbefore_compute = true\rmost_recent = true\rconfiguration_values = jsonencode({\renv = {\rENABLE_POD_ENI = \u0026#34;true\u0026#34;\rENABLE_PREFIX_DELEGATION = \u0026#34;true\u0026#34;\rPOD_SECURITY_GROUP_ENFORCING_MODE = \u0026#34;standard\u0026#34;\r}\rnodeAgent = {\renablePolicyEventLogs = \u0026#34;true\u0026#34;\r}\renableNetworkPolicy = \u0026#34;true\u0026#34;\r})\r}\r}\rvpc_id = module.vpc.vpc_id\rsubnet_ids = module.vpc.private_subnets\rcreate_cluster_security_group = false\rcreate_node_security_group = false\reks_managed_node_groups = {\rdefault = {\rinstance_types = [\u0026#34;m5.large\u0026#34;]\rforce_update_version = true\rrelease_version = var.ami_release_version\ruse_name_prefix = false\riam_role_name = \u0026#34;${var.cluster_name}-ng-default\u0026#34;\riam_role_use_name_prefix = false\rmin_size = 3\rmax_size = 6\rdesired_size = 3\rupdate_config = {\rmax_unavailable_percentage = 50\r}\rlabels = {\rworkshop-default = \u0026#34;yes\u0026#34;\r}\r}\r}\rtags = merge(local.tags, {\r\u0026#34;karpenter.sh/discovery\u0026#34; = var.cluster_name\r})\r} Tạo môi trường workshop với Terraform Đối với cấu hình đã cho, terraform sẽ tạo ra Môi trường Workshop với các bước sau:\nTạo một VPC qua ba AZ Tạo ra một cụm EKS Tạo một nhà cung cấp IAM OIDC Thêm một nhóm node quản lý có tên là default Cấu hình VPC CNI để sử dụng ủy quyền tiền tố Tải các tập tin Terraform về:\n$ mkdir -p ~/environment/terraform; cd ~/environment/terraform $ curl --remote-name-all https://raw.githubusercontent.com/aws-samples/eks-workshop-v2/stable/cluster/terraform/{main.tf,variables.tf,providers.tf,vpc.tf,eks.tf} Chạy các lệnh Terraform sau để triển khai môi trường workshop của bạn.\n$ terraform init $ terraform apply -var=\u0026#34;cluster_name=$EKS_CLUSTER_NAME\u0026#34; -auto-approve Thường mất khoảng 20-25 phút để hoàn thành. Sau khi cụm được tạo ra, chạy lệnh này để sử dụng cụm cho các bài thực hành Lab:\n$ use-cluster $EKS_CLUSTER_NAME Bước Tiếp Theo Bây giờ cụm đã sẵn sàng, hãy đi đến Bắt Đầu hoặc nhảy qua bất kỳ mô-đun nào trong workshop với thanh điều hướng hàng đầu. Khi bạn hoàn thành với workshop, làm theo các bước dưới đây để dọn dẹp môi trường của bạn.\nDọn dẹp Phần sau đây sẽ hướng dẫn cách dọn dẹp các tài nguyên sau khi bạn đã hoàn thành các bài thực hành mong muốn. Những bước này sẽ xóa hết tất cả hạ tầng được cung cấp.\nTrước khi xóa môi trường Cloud9, chúng ta cần dọn dẹp cụm mà chúng ta đã thiết lập ở trên.\nĐầu tiên, sử dụng delete-environment để đảm bảo rằng ứng dụng mẫu và bất kỳ hạ tầng Lab nào còn sót lại đều được loại bỏ:\n$ delete-environment Tiếp theo, xóa cụm với terraform:\n$ cd ~/environment/terraform $ terraform destroy -var=\u0026#34;cluster_name=$EKS_CLUSTER_NAME\u0026#34; -auto-approve "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.2-cluster-creation/",
	"title": "Tạo cụm Kubernetes",
	"tags": [],
	"description": "",
	"content": "Ở bước này, chúng ta tạo một cụm EKS để thực hiện các bài workshop. Vui lòng tuân theo một trong các hướng dẫn dưới đây để cung cấp một cụm phù hợp với yêu cầu của các bài workshop này:\n(Được khuyến nghị) eksctl Terraform CDK (Sẽ ra mắt trong tương lai) "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.1-prepare-environment/2.1.2-cloud-ide/",
	"title": "Triển khai VSCode dưới dạng web host trên EC2 và CloudFront",
	"tags": [],
	"description": "",
	"content": "Lưu ý: Hiện tại AWS sắp ngừng cung cấp Cloud9. Chúng tôi hiện tại đang tìm các giải pháp thay thế sớm nhất có thể.\nHướng dẫn thiết lập môi trường chạy lab trong tài khoản AWS của bạn Bước đầu tiên là tạo một IDE với mẫu CloudFormation được cung cấp. Mở CloudShell tại một trong các region us-west-2, us-east-1 hoặc ap-southeast-1 và chạy các lệnh sau:\n$ wget -q https://raw.githubusercontent.com/longthg-workshops/eks-workshop-v2-fork/cloud-ide/lab/cfn/ec2-workshop-cloud-ide-cfn.yaml -O eks-workshop-ide-cfn.yaml $ aws cloudformation deploy --stack-name eks-workshop-ide \\ --template-file ./eks-workshop-ide-cfn.yaml \\ --parameter-overrides RepositoryRef=stable \\ --capabilities CAPABILITY_NAMED_IAM Waiting for changeset to be created... Waiting for stack create/update to complete Successfully created/updated stack - eks-workshop-ide Một cách khác là sử dụng các link nhanh sau:\nUse the AWS CloudFormation quick-create links below to launch the desired template in the appropriate AWS region.\nRegion Link (Preview) us-west2 Launch eu-west-1 Launch ap-southeast-1 Launch Ba region trên đã được kiểm thử và đảm bảo. Để chạy lab tại các region khác, bạn có thể cần thực hiện một số chỉnh sửa.\nStack sẽ mất từ 4-5 phút để tạo. Sau khi stack hoàn thành, chuyển qua tab output để lấy thông tin truy cập vào IDE:\nKhóa đầu ra IdeUrl chứa URL cần nhập vào trình duyệt của bạn để truy cập IDE. IdePasswordSecret chứa liên kết đến khóa AWS Secrets Manger chứa mật khẩu được tạo cho IDE.\nĐể nhận mật khẩu, mở URL IdePasswordSecret và nhấn nút Retrieve: Mật khẩu để bạn sao chép sẽ hiện lên: Mở URL IdeUrllên và để truy cập trang web IDE. Bạn sẽ nhận thông báo yêu cầu mật khẩu Sau khi nhập mật khẩu, bạn sẽ truy cập được vào màn hình ban đầu của VSCode.\nTrong trường hợp CloudFormation báo lỗi không tạo được CloudFront Distribution do chưa xác thực tài khoản, bạn có thể yêu cầu nâng giới hạn tài nguyên CloudFront Distribution tại đây. Tại mục Service, chọn \u0026ldquo;CloudFront Distribution\u0026rdquo;. Tại mục Request 1, chọn Quota là Web Distributions per Account và đặt giá trị cao hơn giới hạn trước đó của bạn (nếu tài khoản của bạn mới được tạo và bạn chưa dùng CloudFront Distribution trên tài khoản, bạn có thể điền mọi giá trị dương) Tại mục Case description, chép mã lỗi chi tiết tại bước tạo CloudFront Distribution và dán vào khung, kèm miêu tả của bạn về lỗi gặp phải. Sau khi thực hiện xong, chọn phương thức liên hệ. Sau đó nhấn Submit ở cuối trang. Hãy chờ một thời gian, theo dõi case và tích cực trao đổi để được hỗ trợ. Việc chờ xác thực tài khoản va nâng hạn mức\nMở URL này trong trình duyệt web để truy cập vào IDE.\nBạn có thể đóng CloudShell ngay bây giờ, tất cả các lệnh tiếp theo sẽ được thực hiện trong phần terminal ở dưới cùng của Cloud9 IDE. AWS CLI đã được cài đặt sẵn và sẽ nhận các thông tin xác thực được gắn với Cloud9 IDE:\n$ aws sts get-caller-identity Bước tiếp theo là tạo một cụm EKS để thực hiện các bài workshop. Nội dung này sẽ được trình bày tại phần 2.2\n"
},
{
	"uri": "//localhost:1313/vi/3-getting-started/",
	"title": "Bắt đầu",
	"tags": [],
	"description": "",
	"content": "Chào mừng đến với bài thực hành đầu tiên trong bộ Workshop EKS. Mục tiêu của bài tập này là làm quen với ứng dụng mẫu để sử dụng cho nhiều bài tập sắp tới. Trong quá trình đó, chúng ta sẽ đề cập đến một số khái niệm cơ bản liên quan đến việc triển khai khối lượng công việc cho EKS. Chúng ta sẽ tìm hiểu kiến ​​trúc của ứng dụng và triển khai các thành phần cho cụm EKS của mình.\nHãy triển khai khối lượng công việc đầu tiên của bạn cho cụm EKS trong môi trường bài thực hành của bạn và cùng tìm hiểu !\nTrước khi bắt đầu, chúng ta cần chạy lệnh sau để chuẩn bị môi trường IDE và cụm EKS của mình:\n$ prepare-environment introduction/getting-started Lệnh này có tác dụng gì? Đối với bài thực hành này, nó đang sao chép kho lưu trữ Git của EKS Workshop vào môi trường IDE để các tệp kê khai Kubernetes mà chúng ta cần có trên hệ thống tệp.\nBạn sẽ thấy trong các bài thực hành tiếp theo, chúng ta cũng sẽ chạy lệnh này, trong đó nó sẽ thực hiện hai chức năng bổ sung quan trọng:\nĐặt lại cụm EKS về trạng thái ban đầu Cài đặt bất kỳ thành phần bổ sung nào cần thiết vào cụm cho bài tập bài thực hành sắp tới "
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.3-structure/",
	"title": "Cấu trúc workshop",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về cấu trúc các bài lab Nội dung của hội thảo này bao gồm:\nCác bài tập thực hành cá nhân Nội dung hỗ trợ giải thích các khái niệm liên quan đến các bài thực hành Các bài tập thực hành được thiết kế một cách sao cho bạn có thể chạy bất kỳ modules nào như một bài tập độc lập.\nBạn nên bắt đầu mỗi bài lab từ trang đầu tiên. Bắt đầu ở giữa một bài lab sẽ gây ra các biểu hiện không đoán trước được.\nCloud9 IDE Sau khi bạn đã truy cập vào Cloud9 IDE, chúng tôi khuyến nghị bạn sử dụng nút + và chọn New Terminal để mở một cửa sổ terminal mới toàn màn hình.\nĐiều này sẽ mở một tab mới với một terminal mới.\nBạn cũng có thể đóng terminal nhỏ ở dưới nếu bạn muốn.\nCác lệnh Terminal Hầu hết các tương tác mà bạn sẽ thực hiện trong hội thảo này sẽ được thực hiện bằng các lệnh terminal, mà bạn có thể gõ thủ công hoặc sao chép/dán vào terminal Cloud9 IDE. Bạn sẽ thấy các lệnh terminal được hiển thị như sau:\n$ echo \u0026#34;Đây là một ví dụ lệnh\u0026#34; Di chuột qua echo \u0026quot;Đây là một ví dụ lệnh\u0026quot; và nhấp vào biểu tượng để sao chép lệnh đó vào clipboard của bạn.\nBạn cũng sẽ gặp phải các lệnh có kết quả mẫu như sau:\n$ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-42-10-104.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 6h vVAR::KUBERNETES_NODE_VERSION ip-10-42-10-210.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 6h vVAR::KUBERNETES_NODE_VERSION ip-10-42-11-198.us-west-2.compute.internal Ready \u0026lt;none\u0026gt; 6h vVAR::KUBERNETES_NODE_VERSION Giữ chuột, kéo qua lệnh cần sao chép và nhấn Ctrl+C để sao chép. Hãy thử xem!\nThiết lập lại EKS cluster của bạn Trong trường hợp bạn cấu hình cluster theo cách khiến nó không hoạt động, bạn được cung cấp một cơ chế để thiết lập lại EKS cluster của mình sao cho tốt nhất có thể, có thể chạy bất kỳ lúc nào. Đơn giản chỉ cần chạy lệnh prepare-environment và đợi cho đến khi nó hoàn tất. Điều này có thể mất vài phút tùy thuộc vào trạng thái của cluster của bạn khi chạy lệnh này.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.1-cluster/1.1.3-controllers/",
	"title": "Controllers",
	"tags": [],
	"description": "",
	"content": "Trong lĩnh vực robot và tự động hóa, một vòng lặp điều khiển là vòng lặp không kết thúc giúp điều chỉnh trạng thái của một hệ thống.\nDưới đây là một ví dụ về vòng lặp điều khiển: một bộ điều chỉnh nhiệt độ trong phòng.\nKhi bạn thiết lập nhiệt độ, điều đó nghĩa là bạn đang thông báo cho bộ điều chỉnh nhiệt về trạng thái mong muốn của bạn. Nhiệt độ thực tế của phòng là trạng thái hiện tại. - Bộ điều chỉnh nhiệt hoạt động để đưa trạng thái hiện tại gần hơn với trạng thái mong muốn, bằng cách bật hoặc tắt thiết bị. Trong Kubernetes, các controller là các vòng lặp điều khiển quan sát trạng thái của cluster của bạn, sau đó thực hiện hoặc yêu cầu các thay đổi khi cần thiết. Mỗi controller cố gắng di chuyển trạng thái hiện tại của cluster gần hơn với trạng thái mong muốn.\nMô hình Controller Một controller theo dõi ít nhất một loại tài nguyên Kubernetes. Những đối tượng này có một trường spec đại diện cho trạng thái mong muốn. Các controller cho tài nguyên đó chịu trách nhiệm làm cho trạng thái hiện tại gần hơn với trạng thái mong muốn.\nController có thể tự thực hiện hành động; thường thấy hơn, trong Kubernetes, một controller sẽ gửi tin nhắn tới máy chủ API mang lại hiệu ứng hữu ích. Bạn sẽ thấy ví dụ về điều này bên dưới.\nĐiều khiển qua Máy chủ API Controller Job là một ví dụ về controller tích hợp sẵn của Kubernetes. Các controller tích hợp sẵn quản lý trạng thái bằng cách tương tác với máy chủ API của cluster.\nJob là một tài nguyên Kubernetes chạy một Pod, hoặc có thể là nhiều Pods, để thực hiện một nhiệm vụ và sau đó dừng lại.\n(Một khi được lên lịch, các đối tượng Pod trở thành phần của trạng thái mong muốn cho một kubelet).\nKhi controller Job thấy một nhiệm vụ mới, nó đảm bảo rằng, ở đâu đó trong cluster của bạn, các kubelet trên một nhóm Nodes đang chạy số lượng Pods đúng để hoàn thành công việc. Controller Job không chạy bất kỳ Pod hoặc container nào. Thay vào đó, controller Job yêu cầu máy chủ API tạo hoặc xóa Pods. Các thành phần khác trong controller thực hiện theo thông tin mới (có Pods mới cần được lên lịch và chạy), và cuối cùng công việc được hoàn thành.\nSau khi bạn tạo một Job mới, trạng thái mong muốn là cho Job đó được hoàn thành. Controller Job làm cho trạng thái hiện tại của Job đó gần hơn với trạng thái mong muốn: tạo Pods thực hiện công việc bạn muốn cho Job đó, để Job gần hơn với việc hoàn thành.\nCác controller cũng cập nhật các đối tượng cấu hình cho chúng. Ví dụ: một khi công việc được hoàn thành cho một Job, controller Job cập nhật đối tượng Job đó để đánh dấu nó đã hoàn thành.\n(Điều này giống như cách một số bộ điều chỉnh nhiệt tắt đèn để chỉ ra rằng phòng của bạn hiện ở nhiệt độ bạn đã thiết lập).\nĐiều khiển Trực tiếp Trái ngược với Job, một số controller cần thực hiện thay đổi đối với những thứ bên ngoài cluster của bạn.\nVí dụ, nếu bạn sử dụng một vòng lặp điều khiển để đảm bảo có đủ Nodes trong cluster của bạn, thì controller đó cần một thứ gì đó bên ngoài cluster hiện tại để thiết lập Nodes mới khi cần thiết.\nCác controller tương tác với trạng thái bên ngoài tìm trạng thái mong muốn từ máy chủ API, sau đó trực tiếp giao tiếp với một hệ thống bên ngoài để đưa trạng thái hiện tại gần hơn.\n(Thực tế có một controller điều chỉnh quy mô các nodes trong cluster của bạn theo chiều ngang).\nĐiểm quan trọng ở đây là controller thực hiện một số thay đổi để đạt được trạng thái mong muốn, sau đó báo cáo trạng thái hiện tại trở lại máy chủ API của cluster. Các vòng lặp điều khiển khác có thể quan sát dữ liệu được báo cáo và thực hiện các hành động của riêng mình.\nTrong ví dụ về bộ điều chỉnh nhiệt, nếu phòng rất lạnh thì một controller khác cũng có thể bật máy sưởi chống đóng băng. Đối với các cluster Kubernetes, controller gián tiếp làm việc với các công cụ quản lý địa chỉ IP, dịch vụ lưu trữ, API của nhà cung cấp dịch vụ đám mây và các dịch vụ khác bằng cách mở rộng Kubernetes để triển khai điều đó.\nTrạng thái mong muốn và trạng thái hiện tại Kubernetes xem xét hệ thống theo góc nhìn điện toán đám mây, và do đó có thể xử lý các thay đổi.\nCụm của bạn có thể thay đổi bất kỳ lúc nào khi công việc diễn ra và các vòng lặp điều khiển tự động khắc phục lỗi. Điều này có nghĩa: cụm của bạn có thể không bao giờ đạt đến trạng thái ổn định.\nMiễn là controller cụm đang chạy và có thể thực hiện các thay đổi có ích, tính ổn định của trạng thái tổng thể không quan trọng.\nThiết kế Theo nguyên lý thiết kế, Kubernetes sử dụng nhiều controller, mỗi controller quản lý một khía cạnh cụ thể của trạng thái cụm. Thông thường nhất, một vòng lặp điều khiển (hoặc bộ điềuk hiển) cụ thể sử dụng một loại tài nguyên làm trạng thái mong muốn của nó và có một loại tài nguyên khác mà nó quản lý để tạo ra trạng thái mong muốn đó.\nVí dụ: Controller cho Jobs theo dõi các đối tượng Job (để phát hiện công việc mới) và các đối tượng Pod (để chạy Jobs, sau đó xem khi nào công việc hoàn thành). Trong trường hợp này, thứ gì đó khác tạo ra Jobs, trong khi Job controller tạo ra Pod.\nCó thể có nhiều controller cùng tạo hoặc cập nhật chung một loại đối tượng. Thực tế, ở bên dưới, bộ điều khiển Kubernetes đảm bảo rằng chúng chỉ chú ý đến các tài nguyên được liên kết với tài nguyên điều khiển của chúng.\nVí dụ, bạn có thể có Deployments và Jobs; cả hai đều tạo ra Pods. Bộ điều khiển Job không xóa các Pods mà Deployment của bạn đã tạo, vì có thông tin (nhãn) mà bộ điều khiển có thể sử dụng để phân biệt các Pods đó.\nNhững cách thức chạy bộ điều khiển Kubernetes đi kèm với một bộ điều khiển tích hợp chạy bên trong kube-controller-manager. Các bộ điều khiển tích hợp này cung cấp các hành vi cốt lõi quan trọng.\nBộ điều khiển Deployment và bộ điều khiển Job là các ví dụ về bộ điều khiển đi kèm như một phần của chính Kubernetes (bộ điều khiển \u0026ldquo;tích hợp\u0026rdquo;). Kubernetes cho phép bạn chạy một tầng điều khiển dự phòng, do đó nếu bất kỳ bộ điều khiển tích hợp nào bị lỗi, một phần khác của tầng điều khiển sẽ tiếp quản công việc.\nBạn cũng sẽ thấy các bộ điều khiển chạy bên ngoài tầng điều khiển để mở rộng Kubernetes. Hoặc, nếu muốn, bạn có thể tự viết một bộ điều khiển mới. Bạn có thể chạy bộ điều khiển của riêng mình dưới dạng một bộ Pod hoặc bên ngoài Kubernetes. Bộ điều khiển nào phù hợp nhất sẽ phụ thuộc vào chức năng của bộ điều khiển cụ thể đó.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.3-etcd/",
	"title": "ETCD",
	"tags": [],
	"description": "",
	"content": " ETCD là một hệ thống lưu trữ key-value phân tán, đáng tin cậy, đơn giản, an toàn và nhanh chóng. Key-Value Store là gì? Từ trước đến nay, Key-Value Store là cơ sở dữ liệu được lưu trữ dưới dạng bảng, bạn có thể đã nghe về SQL hoặc cơ sở dữ liệu quan hệ. Chúng lưu trữ dữ liệu theo dòng và cột.\nMột Key-Value Store lưu trữ thông tin dưới dạng Key và Value.\nCài đặt ETCD Việc cài đặt và bắt đầu với ETCD rất dễ dàng.\nTải xuống file thực thi phù hợp với hệ điều hành của bạn từ trang phát hành trên Github (ETCD Releases)\nVí dụ: Để tải xuống ETCD v3.5.6, chạy lệnh curl sau:\n$ curl -LO https://github.com/etcd-io/etcd/releases/download/v3.5.6/etcd-v3.5.6-linux-amd64.tar.gz Giải nén nó. $ tar xvzf etcd-v3.5.6-linux-amd64.tar.gz Chạy dịch vụ ETCD. $ ./etcd Khi khởi động ETCD, mặc định nó sẽ tiếp nhận yêu cầu trên cổng 2379.\nClient mặc định đi kèm với ETCD là etcdctl. Bạn có thể sử dụng nó để lưu trữ và truy xuất cặp key-value.\nCú pháp: Để lưu một cặp Key-Value.\n$ ./etcdctl put key1 value1 Cú pháp: Để truy xuất dữ liệu đã lưu. $ ./etcdctl get key1 Cú pháp: Để xem thêm các lệnh. Chạy etcdctl mà không cần bất kỳ đối số nào. $ ./etcdctl Bộ lưu Dữ Liệu ETCD Bộ lưu Dữ Liệu ETCD lưu trữ thông tin về cluster như Nodes, PODS, Configs, Secrets, Accounts, Roles, Bindings và các thông tin khác. Mọi thông tin bạn thấy khi chạy lệnh kubectl get đều đến từ Máy chủ ETCD.\nCài đặt - Thủ công Nếu bạn thiết lập cluster từ số không, bạn sẽ phải triển khai ETCD bằng cách tự tải xuống các tệp thực thi ETCD.\nCài đặt các tệp thực thi và cấu hình ETCD như một dịch vụ trên node master của bạn.\n$ wget -q --https-only \u0026#34;https://github.com/etcd-io/etcd/releases/download/v3.3.11/etcd-v3.3.11-linux-amd64.tar.gz\u0026#34; etcd Cài đặt - Kubeadm Nếu bạn thiết lập cluster sử dụng kubeadm, thì kubeadm sẽ triển khai máy chủ etcd cho bạn dưới dạng một pod trong không gian tên kube-system. $ kubectl get pods -n kube-system etcd1 Tìm hiểu về ETCD Để liệt kê tất cả các khóa được lưu trữ bởi kubernetes, chạy lệnh dưới đây: $ kubectl exec etcd-master -n kube-system -- sh -c \u0026#34;ETCDCTL_API=3 etcdctl --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt get / --prefix --keys-only\u0026#34; Kubernetes lưu trữ dữ liệu trong một cấu trúc thư mục cụ thể, thư mục gốc là registry và dưới đó bạn có các cấu trúc kubernetes khác như minions, nodes, pods, replicasets, deployments, roles, secrets và các thông tin khác. ETCD trong Môi Trường HA (High Availability) Trong một môi trường có khả năng cao sẵn sàng, cluster của bạn sẽ có nhiều node master, sẽ có nhiều thể hiện ETCD được phân bố trên các node master này.\nĐảm bảo các thể hiện ETCD biết về nhau bằng cách thiết lập tham số đúng trong cấu hình etcd.service. Tùy chọn \u0026ndash;initial-cluster nơi bạn cần chỉ định các thể hiện khác nhau của dịch vụ etcd.\nTài liệu tham khảo https://kubernetes.io/docs/concepts/overview/components/ https://etcd.io/docs/ https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/ https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/ https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/#stacked-control-plane-and-etcd-nodes https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/#external-etcd-nodes "
},
{
	"uri": "//localhost:1313/vi/3-getting-started/3-deploying-our-first-component/",
	"title": "Triển khai thành phần đầu tiên",
	"tags": [],
	"description": "",
	"content": "Triển khai Ứng dụng mẫu Ứng dụng mẫu được tạo thành từ một tập hợp các tuyên bố Kubernetes được tổ chức một cách dễ dàng áp dụng bằng Kustomize. Kustomize là một công cụ mã nguồn mở cũng được cung cấp như một tính năng gốc của CLI kubectl. Hội thảo này sử dụng Kustomize để áp dụng các thay đổi vào các tuyên bố Kubernetes, giúp việc hiểu các thay đổi đối với các tệp tuyên bố mà không cần phải chỉnh sửa YAML thủ công. Khi chúng ta làm việc qua các module khác nhau của hội thảo này, chúng ta sẽ áp dụng các overlay và patch một cách từ từ bằng Kustomize.\nCách dễ nhất để duyệt các tuyên bố YAML cho ứng dụng mẫu và các module trong hội thảo này là sử dụng trình duyệt tệp trong Cloud9:\nMở rộng các mục eks-workshop và sau đó base-application sẽ cho phép bạn duyệt các tuyên bố tạo thành trạng thái ban đầu của ứng dụng mẫu:\nCấu trúc bao gồm một thư mục cho mỗi thành phần ứng dụng được mô tả trong phần Ứng dụng mẫu.\nThư mục modules chứa các bộ tuyên bố mà chúng ta sẽ áp dụng vào cụm trong các bài tập thực hành lab sau:\nTrước khi làm bất kỳ điều gì, hãy kiểm tra các Namespaces hiện tại trong cụm EKS của chúng ta:\n$ kubectl get namespaces NAME STATUS AGE default Active 1h kube-node-lease Active 1h kube-public Active 1h kube-system Active 1h Tất cả các mục liệt kê là Namespaces cho các thành phần hệ thống đã được cài đặt sẵn cho chúng ta. Chúng ta sẽ bỏ qua chúng bằng cách sử dụng nhãn Kubernetes để lọc các Namespaces chỉ xuống các Namespaces mà chúng ta đã tạo:\n$ kubectl get namespaces -l app.kubernetes.io/created-by=eks-workshop No resources found Điều đầu tiên chúng ta sẽ làm là triển khai thành phần catalog một mình. Các tuyên bố cho thành phần này có thể được tìm thấy trong ~/environment/eks-workshop/base-application/catalog.\n$ ls ~/environment/eks-workshop/base-application/catalog configMap.yaml deployment.yaml kustomization.yaml namespace.yaml secrets.yaml service-mysql.yaml service.yaml serviceAccount.yaml statefulset-mysql.yaml Các tuyên bố này bao gồm Deployment cho API catalog:\nmanifests/base-application/catalog/deployment.yaml Deployment này diễn đạt trạng thái mong muốn của thành phần API catalog:\nSử dụng hình ảnh container public.ecr.aws/aws-containers/retail-store-sample-catalog Chạy một bản sao duy nhất Tiếp tục container trên cổng 8080 có tên là http Chạy probes/healthchecks chống lại đường dẫn /health Requests một lượng CPU và bộ nhớ cụ thể để lập lịch Kubernetes có thể đặt nó trên một nút với đủ tài nguyên khả dụng Áp dụng các nhãn cho các Pod để các tài nguyên khác có thể tham chiếu đến chúng Các tuyên bố cũng bao gồm Service được sử dụng bởi các thành phần khác để truy cập API catalog:\nmanifests/base-application/catalog/service.yaml Service này:\nLựa chọn các Pod catalog bằng cách sử dụng các nhãn phù hợp với những gì chúng ta đã diễn đạt trong Deployment ở trên Mở bản thân trên cổng 80 Chỉ định cổng http được mở bởi Deployment, đồng nghĩa với cổng 8080 Hãy tạo thành phần catalog:\n$ kubectl apply -k ~/environment/eks-workshop/base-application/catalog namespace/catalog created serviceaccount/catalog created configmap/catalog created secret/catalog-db created service/catalog created service/catalog-mysql created deployment.apps/catalog created statefulset.apps/catalog-mysql created Bây giờ chúng ta sẽ thấy một Namespace mới:\n$ kubectl get namespaces -l app.kubernetes.io/created-by=eks-workshop NAME STATUS AGE catalog Active 15s Chúng ta có thể xem các Pod đang chạy trong namespace này:\n$ kubectl get pod -n catalog NAME READY STATUS RESTARTS AGE catalog-846479dcdd-fznf5 1/1 Running 2 (43s ago) 46s catalog-mysql-0 1/1 Running 0 46 Bạn đã hoàn thành việc triển khai thành phần catalog thành công.\n"
},
{
	"uri": "//localhost:1313/vi/2-prerequiste/2.1-prepare-environment/2.1.3-remote-vscode/",
	"title": "Triển khai VSCode Server trên EC2 và truy cập bằng VSCode trên máy của bạn",
	"tags": [],
	"description": "",
	"content": "Tạo Key Pair Nếu bạn đã tạo và lưu sẵn Key Pair, bạn có thể bỏ qua bước này và chuyển sang bước tiếp theo.\nĐầu tiên, bạn cần vào bảng điều khiển EC2. Tại đây, ở thanh điều hướng bên trái, chọn Key Pairs. Ở giao diện Key Pairs, chọn Create Key Pair.\nTại giao diện Create Key Pair:\nTại mục Name, nhập tên tùy ý cho Key Pair. Tiếp đến, chọn một trong hai loại khóa và định dạng .pem. Nhấn nút Create key pair ở cuối (màu cam) để tiến hành tạo khóa. Lưu file private key trên máy tính. Khóa này sẽ được dùng để gắn vào EC2 được tạo ở bước kế tiếp.\nHãy đảm bảo chỉ có bạn mới có thể truy cập vào file .pem.\nVới Linux, sử dụng lệnh: chmod 400 \u0026lt;đường dẫn tới file pem\u0026gt; Với Windows, đảm bảo quyền truy cập của bạn như sau: Tạo CloudFormation Stack Tải tệp template tại link này.\nTruy cập giao diện CloudFormation\nChọn Create Stack. Nhập tên cho Stack Name và Environment Name.\nVới SshKeyName, nhập tên của Key Pair đã tạo ở bước trước đó.\nNhấn Next qua các bước và đợi đến khi Stack được tạo xong.\nCấu hình kết nối SSH trên máy tính của bạn Tại giao diện của CloudFormation stack đã tạo, chuyển sang mục Output. Tìm khóa IdeInstancePublicIP, giá trị của khóa này chính là địa chỉ cần kết nối đến.\nThêm vào file C:\\Users\\\u0026lt;Tên người dùng\u0026gt;\\.ssh\\config (nếu bạn đang dùng Windows) hoặc ~/.ssh/config (nếu bạn đang dùng Linux):\nHost remote-connection\rHostName \u0026lt;public ip của EC2\u0026gt;\rUser ec2-user\rIdentityFile \u0026#34;\u0026lt;đường dẫn đến file pem đã lưu\u0026gt;\u0026#34; Kết nối VSCode đến EC2 Cài đặt tiện ích Remote-SSH để hỗ trợ việc kết nối vối SSH Host Sau khi cài đặt tiện ích, bạn sẽ nhìn thấy icon ở phía dưới bên trái của màn hình.\nẤn vào icon để mở bảng chọn kết nối. Chọn “Connect to Host…”\nChọn “Add New SSH Host” để tạo một SSH Host mới Chọn C:\\Users\\\u0026lt;tên người dùng\u0026gt;\\.ssh\\config để mở file config\nSau khi thiết lập xong, bạn ấn vào icon để mở bạng chọn và điều hướng tới “remote-connection”\nTiếp theo, bạn chọn Platform details “Linux” và chọn “Continue” Nếu thành công, một cửa sổ VSCode mới sẽ mở lên và bạn sẽ được truy cập vào EC2. Chọn \u0026ldquo;File \u0026gt; Open\u0026rdquo; để mở thư mục\nChọn thư mục /home/\u0026lt; tên người dùng \u0026gt;/environment\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.4-kube-api-server/",
	"title": "Kube API Server",
	"tags": [],
	"description": "",
	"content": "Kube-apiserver là thành phần chính trong Kubernetes. Kube-apiserver chịu trách nhiệm xác thực, kiểm tra yêu cầu, truy xuất và cập nhật dữ liệu trong cửa hàng khóa-giá trị ETCD. Thực tế, kube-apiserver là thành phần duy nhất tương tác trực tiếp với cơ sở dữ liệu etcd. Các thành phần khác như kube-scheduler, kube-controller-manager và kubelet sử dụng API-Server để cập nhật trong cụm ở các lĩnh vực tương ứng của họ.\nCài đặt kube-apiserver Nếu bạn đang khởi động kube-apiserver sử dụng công cụ kubeadm, thì bạn không cần phải biết điều này, nhưng nếu bạn đang thiết lập theo cách thủ công, thì kube-apiserver có sẵn dưới dạng một tệp nhị phân trên trang phát hành Kubernetes. Ví dụ: Bạn có thể tải xuống nhị phân kube-apiserver v1.13.0 tại đây:\n$ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-apiserver Xem kube-apiserver - Kubeadm Kubeadm triển khai kube-apiserver dưới dạng một pod trong namespace kube-system trên node master. $ kubectl get pods -n kube-system Xem các tùy chọn của kube-apiserver - Kubeadm Bạn có thể xem các tùy chọn trong tệp định nghĩa pod tại /etc/kubernetes/manifests/kube-apiserver.yaml $ cat /etc/kubernetes/manifests/kube-apiserver.yaml Xem các tùy chọn của kube-apiserver - Cách thủ công Trong một cài đặt không sử dụng kubeadm, bạn có thể kiểm tra các tùy chọn bằng cách xem dịch vụ kube-apiserver.service $ cat /etc/systemd/system/kube-apiserver.service Bạn cũng có thể xem quá trình đang chạy và các tùy chọn hiệu quả bằng cách liệt kê quá trình trên node master và tìm kiếm kube-apiserver $ ps -aux | grep kube-apiserver Tài liệu tham khảo K8s: Kube API Server Command Line Tools Reference Kubernetes Components Overview Kubernetes API Overview Accessing Kubernetes Cluster Accessing Kubernetes Cluster API "
},
{
	"uri": "//localhost:1313/vi/4-kustomize/",
	"title": "Kustomize",
	"tags": [],
	"description": "",
	"content": "Kustomize Kustomize cho phép bạn quản lý các tệp mẫu Kubernetes bằng cách sử dụng các tệp \u0026ldquo;kustomization\u0026rdquo; bằng cách khai báo. Nó cung cấp khả năng diễn đạt các tài nguyên Kubernetes \u0026ldquo;cơ bản\u0026rdquo; cho tài nguyên Kubernetes của bạn và sau đó áp dụng các thay đổi bằng cách sử dụng sự hợp thành, tùy chỉnh và dễ dàng thực hiện các thay đổi chéo qua nhiều tài nguyên.\nVí dụ, hãy xem tệp mẫu sau cho checkout Deployment:\nmanifests/base-application/checkout/deployment.yaml Tệp này đã được áp dụng trong bài lab Getting Started trước đó, nhưng giả sử chúng ta muốn mở rộng thành phần này theo chiều ngang bằng cách cập nhật trường replicas sử dụng Kustomize. Thay vì cập nhật tệp YAML này thủ công, chúng ta sẽ sử dụng Kustomize để cập nhật trường spec/replicas từ 1 thành 3.\nĐể làm điều này, chúng ta sẽ áp dụng kustomization sau.\nTab đầu tiên hiển thị kustomization chúng ta đang áp dụng Tab thứ hai hiển thị một bản xem trước về cách tệp Deployment/checkout được cập nhật sau khi kustomization được áp dụng Cuối cùng, tab thứ ba chỉ hiển thị sự khác biệt của những thay đổi đã xảy ra modules/introduction/kustomize/deployment.yaml\rDeployment/checkout Bạn có thể tạo ra YAML Kubernetes cuối cùng áp dụng kustomization này bằng lệnh kubectl kustomize, mà gọi kustomize được gói kèm với CLI kubectl:\n$ kubectl kustomize ~/environment/eks-workshop/modules/introduction/kustomize Điều này sẽ tạo ra nhiều tệp YAML, đại diện cho các tài nguyên cuối cùng bạn có thể áp dụng trực tiếp vào Kubernetes. Hãy minh họa điều này bằng cách chuyển dữ liệu đầu ra từ kustomize trực tiếp sang kubectl apply:\n$ kubectl kustomize ~/environment/eks-workshop/modules/introduction/kustomize | kubectl apply -f - namespace/checkout unchanged serviceaccount/checkout unchanged configmap/checkout unchanged service/checkout unchanged service/checkout-redis unchanged deployment.apps/checkout configured deployment.apps/checkout-redis unchanged Bạn sẽ nhận thấy một số tài nguyên liên quan đến checkout \u0026ldquo;unchanged\u0026rdquo;, với deployment.apps/checkout được \u0026ldquo;cấu hình\u0026rdquo;. Điều này là có chủ ý — chúng ta chỉ muốn áp dụng các thay đổi vào deployment của checkout. Điều này xảy ra vì lệnh trước đó thực sự áp dụng hai tệp: deployment.yaml của Kustomize mà chúng ta đã thấy ở trên, cũng như tệp kustomization.yaml sau đây khớp với tất cả các tệp trong thư mục ~/environment/eks-workshop/base-application/checkout. Trường patches chỉ định tệp cụ thể cần được vá:\nmanifests/modules/introduction/kustomize/kustomization.yaml Để kiểm tra xem số bản sao đã được cập nhật, chạy lệnh sau:\n$ kubectl get pod -n checkout -l app.kubernetes.io/component=service NAME READY STATUS RESTARTS AGE checkout-585c9b45c7-c456l 1/1 Running 0 2m12s checkout-585c9b45c7-b2rrz 1/1 Running 0 2m12s checkout-585c9b45c7-xmx2t 1/1 Running 0 40m Thay vì sử dụng sự kết hợp của kubectl kustomize và kubectl apply, chúng ta có thể thực hiện cùng một việc với kubectl apply -k \u0026lt;thư_mục_kustomization\u0026gt; (chú ý cờ -k thay vì -f). Phương pháp này được sử dụng trong khóa học này để làm cho việc áp dụng các thay đổi vào các tệp mẫu dễ dàng hơn, trong khi rõ ràng hiển thị các thay đổi cần được áp dụng.\nHãy thử:\n$ kubectl apply -k ~/environment/eks-workshop/modules/introduction/kustomize Để đặt lại các tệp mẫu ứng dụng về trạng thái ban đầu của chúng, bạn có thể đơn giản áp dụng bộ tệp mẫu ban đầu:\n$ kubectl apply -k ~/environment/eks-workshop/base-application Mẫu khác bạn sẽ thấy được sử dụng trong một số bài lab có dạng như sau:\n$ kubectl kustomize ~/environment/eks-workshop/base-application \\ | envsubst | kubectl apply -f- Điều này sử dụng envsubst để thay thế các nơi giữ chỗ biến môi trường trong các tệp mẫu Kubernetes bằng các giá trị thực tế dựa trên môi trường cụ thể của bạn. Ví dụ trong một số tệp mẫu, chúng ta cần tham chiếu đến tên cụm EKS với $EKS_CLUSTER_NAME hoặc khu vực AWS với $AWS_REGION.\nBây giờ bạn đã hiểu cách Kustomize hoạt động, tiến hành module Cơ bản.\nĐể tìm hiểu thêm về Kustomize, bạn có thể tham khảo tài liệu chính thức của Kubernetes.\n"
},
{
	"uri": "//localhost:1313/vi/3-getting-started/4-microservices-on-kubernetes/",
	"title": "Microservices trên Kubernetes",
	"tags": [],
	"description": "",
	"content": "Microservices trên Kubernetes Bây giờ khi chúng ta đã quen với kiến trúc tổng quan của ứng dụng mẫu, chúng ta sẽ bắt đầu triển khai vào EKS như thế nào? Hãy tìm hiểu một số cách xây dựng Kubernetes bằng cách xem component catalog:\nCó một số điều cần xem xét trong biểu đồ này:\nỨng dụng cung cấp catalog API chạy như một Pod, đây là đơn vị triển khai nhỏ nhất trong Kubernetes. Các Application Pods sẽ chạy các container images mà chúng ta đã trình bày trong phần trước đó. Các Pods chạy catalog component được tạo bởi một Deployment có thể quản lý một hoặc nhiều \u0026ldquo;bản sao\u0026rdquo; của catalog Pod, cho phép nó mở rộng theo chiều ngang. Một Service là một cách trừu tượng để tiết lộ một ứng dụng đang chạy dưới dạng một tập hợp các Pods, và điều này cho phép catalog API của chúng ta được gọi bởi các components khác bên trong Kubernetes cluster. Mỗi Service đều có một mục nhập DNS riêng. Chúng ta bắt đầu workshop này với một cơ sở dữ liệu MySQL chạy bên trong Kubernetes cluster của chúng tôi dưới dạng một StatefulSet, được thiết kế để quản lý các stateful workloads. Tất cả các Kubernetes constructs này được nhóm lại trong Namespace catalog riêng của chúng. Mỗi application component đều có Namespace riêng của nó. Mỗi trong số các components trong kiến trúc microservices là một cách khái niệm tương tự catalog, sử dụng Deployments để quản lý application workload Pods và Services để định tuyến lưu lượng đến các Pods đó. Nếu chúng ta mở rộng tầm nhìn của mình về kiến trúc, chúng ta có thể xem xét cách lưu lượng được định tuyến trong toàn hệ thống rộng lớn hơn:\nComponent ui nhận yêu cầu HTTP từ, ví dụ, trình duyệt của người dùng. Sau đó, nó thực hiện các yêu cầu HTTP đến các API components khác trong kiến trúc để thực hiện yêu cầu đó và trả về một phản hồi cho người dùng. Mỗi trong số các downstream components có thể có data stores hoặc cơ sở hạ tầng khác của riêng mình. Namespaces là một nhóm logic của các resources cho mỗi microservice và cũng hoạt động như một ranh giới cách ly mềm, có thể được sử dụng để triển khai hiệu quả các điều khiển sử dụng Kubernetes RBAC và Network Policies.\n"
},
{
	"uri": "//localhost:1313/vi/3-getting-started/5-other-components/",
	"title": "Các thành phần khác",
	"tags": [],
	"description": "",
	"content": "Trong bài thực hành này, chúng ta sẽ triển khai phần còn lại của ứng dụng mẫu một cách hiệu quả bằng cách sử dụng sức mạnh của Kustomize. File kustomization sau đây cho thấy cách bạn có thể tham chiếu đến các kustomizations khác và triển khai nhiều thành phần cùng nhau:\nmanifests/base-application/kustomization.yaml Lưu ý rằng API danh mục nằm trong kustomization này, chúng ta đã triển khai nó chưa?\nBởi vì Kubernetes sử dụng cơ chế khai báo, chúng ta có thể áp dụng các manifests cho API danh mục một lần nữa và mong đợi rằng vì tất cả các tài nguyên đã được tạo ra, Kubernetes sẽ không thực hiện bất kỳ hành động nào.\nÁp dụng kustomization này vào cluster của chúng ta để triển khai các thành phần còn lại:\n$ kubectl apply -k ~/environment/eks-workshop/base-application Sau khi hoàn thành điều này, chúng ta có thể sử dụng kubectl wait để đảm bảo rằng tất cả các thành phần đã được bắt đầu trước khi chúng ta tiếp tục:\n$ kubectl wait --for=condition=Ready --timeout=180s pods \\ -l app.kubernetes.io/created-by=eks-workshop -A Bây giờ chúng ta sẽ có một Namespace cho mỗi thành phần ứng dụng của chúng ta:\n$ kubectl get namespaces -l app.kubernetes.io/created-by=eks-workshop NAME STATUS AGE assets Active 62s carts Active 62s catalog Active 7m17s checkout Active 62s orders Active 62s other Active 62s rabbitmq Active 62s ui Active 62s Chúng ta cũng có thể thấy tất cả các Deployments được tạo ra cho các thành phần:\n$ kubectl get deployment -l app.kubernetes.io/created-by=eks-workshop -A NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE assets assets 1/1 1 1 90s carts carts 1/1 1 1 90s carts carts-dynamodb 1/1 1 1 90s catalog catalog 1/1 1 1 7m46s checkout checkout 1/1 1 1 90s checkout checkout-redis 1/1 1 1 90s orders orders 1/1 1 1 90s orders orders-mysql 1/1 1 1 90s ui ui 1/1 1 1 90s Ứng dụng mẫu hiện đã được triển khai và sẵn sàng cung cấp một nền tảng cho chúng ta để sử dụng trong các bài thực hành khác trong workshop này!\n"
},
{
	"uri": "//localhost:1313/vi/5-helm/",
	"title": "Helm",
	"tags": [],
	"description": "",
	"content": "Mặc dù chúng ta chủ yếu tương tác với tùy chỉnh trong bộ workshop này, sẽ có những tình huống Helm được sử dụng để cài đặt một số gói nhất định trong cụm EKS. Trong bài thực hành này, chúng tôi giới thiệu ngắn gọn về Helm cùng cách sử dụng nó để cài đặt một ứng dụng đóng gói sẵn.\nChuẩn bị môi trường Chạy lệnh sau để chuẩn bị môi trường cho lab:\nprepare-environment introduction/helm Helm là trình quản lý gói dành cho Kubernetes giúp xác định, cài đặt và nâng cấp các ứng dụng Kubernetes. Nó sử dụng định dạng đóng gói được gọi là \u0026ldquo;chart\u0026rdquo;, chứa tất cả các định nghĩa tài nguyên Kubernetes cần thiết để chạy một ứng dụng. Helm đơn giản hóa việc triển khai và quản lý ứng dụng trên cụm Kubernetes.\nHelm CLI Cung cấp CLI cho phép nhà phát triển quản lý, khởi tạo, phát triển các Charts, Config, Release, Repositores một cách tự động. Để sử dụng Helm CLI kiểm tra phiên bản Helm nào đã được cài đặt, chạy lệnh sau:\n$ helm version Helm Repo Kho lưu trữ Helm là nơi tập trung các Helm Chart nhằm lưu trữ và quản lý.\nỞ dưới đây là các lệnh để thêm, cập nhật và tìm kiếm kho Helm Bitnami. Đây là nơi lưu trữ một số ứng dụng/dịch vụ phổ biến trên Kubernetes:\n$ helm repo add bitnami https://charts.bitnami.com/bitnami $ helm repo update $ helm search repo postgresql NAME CHART VERSION APP VERSION DESCRIPTION bitnami/postgresql X.X.X X.X.X PostgreSQL (Postgres) is an open source object-... [...] Cài đặt Helm chart $ echo $NGINX_CHART_VERSION $ helm install nginx bitnami/nginx \\ --version $NGINX_CHART_VERSION \\ --namespace nginx --create-namespace --wait Các thành phần câu lệnh:\nLệnh con install thực hiện công việc cài đặt Helm chart. Các Helm chart có thể được nâng cấp hoặc quay lại phiên bản cũ. nginx là tên của bản triển khai trên cụm EKS của bạn. bitnami/nginx chính là tên của chart nginx trên kho bitnami. Tham số --version xác định phiên bản của chart được cài đặt. Cờ --create-namespace sẽ tạo namespace mới với tên đã xác định bằng tham số --namespace. Liệt kê chart đã cài đặt $ helm list -A NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION nginx\tnginx 1 2024-06-11 03:58:39.862100855 +0000 UTC deployed nginx-X.X.X X.X.X Liệt kê các pod thuộc chart đã cài đặt:\n$ kubectl get pod -n nginx NAME READY STATUS RESTARTS AGE nginx-55fbd7f494-zplwx 1/1 Running 0 119s Cấu hình các giá trị trong chart Tại thư mục chính của chart, có một tệp với tên value.yaml. Tệp này được dùng để xác định các giá trị và truyền vào chart. Để thay thế các giá trị mặc định, ta có thể dùng một trong các cách sau:\nTạo file yaml và truyền giá trị vào đó qua các tham số -f hoặc --values. Sử dụng cờ --set với cặp khoá - giá trị key=value. Chúng ta kết hợp cả hai bằng các tạo tệp YAML sau:\n~/environment/eks-workshop/modules/introduction/helm/values.yaml podLabels: team: team1 costCenter: org1 resources: requests: cpu: 250m memory: 256Mi Ta triển khai các 3 bản sao bằng lệnh sau:\nhelm upgrade --install nginx bitnami/nginx \\ --version $NGINX_CHART_VERSION \\ --namespace nginx --create-namespace --wait \\ --set replicaCount=3 \\ --values ~/environment/eks-workshop/modules/introduction/helm/values.yaml Kiểm tra lịch sử triển khai Helm chart:\n$ helm history nginx -n nginx REVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Tue Jun 11 03:58:39 2024 superseded nginx-X.X.X X.X.X Install complete 2 Tue Jun 11 04:13:53 2024 deployed nginx-X.X.X X.X.X Upgrade complete Gỡ cài đặt Helm chart Để gỡ Helm chart nginx trong namespace nginx, chạy lệnh sau:\n$ helm uninstall nginx --namespace nginx --wait "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.5-kube-controller-manager/",
	"title": "Kube Controller Manager",
	"tags": [],
	"description": "",
	"content": " Trình quản lý bộ điều khiển Kubernetes (Kube Controller Manager) quản lý các bộ điều khiển khác nhau trong Kubernetes. Trong thuật ngữ của Kubernetes, một bộ điều khiển là một quá trình liên tục theo dõi trạng thái của các thành phần bên trong hệ thống và làm việc nhằm đưa toàn bộ hệ thống về trạng thái hoạt động mong muốn. Bộ Điều Khiển Nút (Node Controller) Chịu trách nhiệm giám sát trạng thái của các Nút (Nodes) và thực hiện các hành động cần thiết để duy trì ứng dụng hoạt động. Bộ Điều Khiển Sao Chép (Replication Controller) Chịu trách nhiệm theo dõi trạng thái của các replica sets và đảm bảo số lượng pods mong muốn luôn sẵn có trong bộ. Cài Đặt Trình Quản Lý Bộ Điều Khiển Kube (Kube-Controller-Manager) Khi bạn cài đặt kube-controller-manager, các bộ điều khiển khác nhau cũng sẽ được cài đặt. Tải xuống nhị phân kube-controller-manager từ trang phát hành Kubernetes. Ví dụ: Bạn có thể tải xuống kube-controller-manager v1.13.0 tại đây kube-controller-manager $ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-controller-manager Mặc định, tất cả các bộ điều khiển đều được bật, nhưng bạn có thể chọn bật một số bộ điều khiển cụ thể từ kube-controller-manager.service\n$ cat /etc/systemd/system/kube-controller-manager.service Xem kube-controller-manager - kubeadm Kubeadm triển khai kube-controller-manager dưới dạng một pod trong namespace kube-system $ kubectl get pods -n kube-system Xem các tùy chọn kube-controller-manager - kubeadm Bạn có thể xem các tùy chọn trong pod tại /etc/kubernetes/manifests/kube-controller-manager.yaml $ cat /etc/kubernetes/manifests/kube-controller-manager.yaml Xem các tùy chọn kube-controller-manager - Thủ công Trong cài đặt không phải kubeadm, bạn có thể kiểm tra các tùy chọn bằng cách xem kube-controller-manager.service $ cat /etc/systemd/system/kube-controller-manager.service Bạn cũng có thể xem quá trình đang chạy và các tùy chọn hiệu quả bằng cách liệt kê quá trình trên nút master và tìm kiếm kube-controller-manager. $ ps -aux | grep kube-controller-manager Tài Liệu Tham Khảo K8s: Kubernetes Command Line Tools Reference - kube-controller-manager Kubernetes Concepts Overview - Components "
},
{
	"uri": "//localhost:1313/vi/6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Trước khi xoá CloudFormation Stack của workshop, hãy đảm bảo rằng bạn đã xoá các tài nguyên lab và cụm EKS như được hướng dẫn ở phần 2.1 hoặc 2.2 (tuỳ theo hình thức triển khai tài nguyên eksctl và Terraform tương ứng).\nSau khi thực hiện xong bước trên, chạy lệnh sau trên giao diện dòng lệnh CloudShell để xoá tài nguyên Cloud9 IDE:\naws cloudformation delete-stack --stack-name eks-workshop-ide "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.6-kube-scheduler/",
	"title": "Kube Scheduler",
	"tags": [],
	"description": "",
	"content": "kube-scheduler là gì? kube-scheduler chịu trách nhiệm lên lịch cho các pod trên các node. kube-scheduler chỉ quyết định pod nào sẽ được đặt trên node nào. Nó không thực sự đặt pod lên các node, đó là công việc của kubelet. Tại sao bạn cần một trình lên lịch (Scheduler)? kube-scheduler đóng vai trò quan trọng trong việc quản lý tài nguyên và đảm bảo rằng các pod được phân bổ một cách hiệu quả trên các node. Cài đặt kube-scheduler - Thủ công Để tải xuống nhị phân kube-scheduler từ các trang phát hành của Kubernetes, bạn có thể thực hiện như sau. Ví dụ: Để tải xuống kube-scheduler v1.13.0, hãy chạy lệnh dưới đây. $ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler Sau đó, giải nén và chạy nó như một dịch vụ. Xem các tùy chọn của kube-scheduler - kubeadm Nếu bạn thiết lập nó bằng công cụ kubeadm, công cụ này sẽ triển khai kube-scheduler dưới dạng pod trong namespace kube-system trên node master. $ kubectl get pods -n kube-system Bạn có thể xem các tùy chọn cho kube-scheduler trong tệp định nghĩa pod tại /etc/kubernetes/manifests/kube-scheduler.yaml. $ cat /etc/kubernetes/manifests/kube-scheduler.yaml Bạn cũng có thể xem quy trình đang chạy và các tùy chọn hiệu quả bằng cách liệt kê quy trình trên node master và tìm kiếm kube-scheduler. $ ps -aux | grep kube-scheduler Tài liệu tham khảo K8s: Tài liệu tham khảo dòng lệnh kube-scheduler Scheduling và Eviction với kube-scheduler Các thành phần tổng quan Cấu hình nhiều trình lên lịch "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.7-kubelet/",
	"title": "Kubelet",
	"tags": [],
	"description": "",
	"content": "Kubelet Kubelet là một trong những thành phần quan trọng của Kubernetes. Nó chịu trách nhiệm quản lý và duy trì các container chạy trên mỗi node trong cụm Kubernetes.\nMặc định, Kubeadm không triển khai Kubelet. Bạn cần phải tự tải về và cài đặt nó.\nCài đặt Kubelet Để cài đặt Kubelet, bạn có thể tải file nhị phân từ trang phát hành Kubernetes tại đây. Ví dụ: Để tải về Kubelet v1.13.0, sử dụng lệnh sau.\n$ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet Sau khi tải xuống, giải nén file và chạy nó như một dịch vụ.\nĐể xem các tùy chọn của Kubelet và quá trình đang chạy, bạn có thể sử dụng lệnh sau trên node worker:\n$ ps -aux | grep kubelet Tài liệu tham khảo Kubernetes: Command Line Tools Reference - Kubelet Overview Components Kubeadm Kubelet Integration "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.8-kube-proxy/",
	"title": "kube-proxy",
	"tags": [],
	"description": "",
	"content": "Trong cụm Kubernetes, mỗi pod có thể kết nối với mọi pod khác, điều này được thực hiện bằng cách triển khai một cụm mạng pod vào cụm.\nkube-Proxy là một quy trình công việc chạy trên mỗi node trong cụm Kubernetes.\nCài đặt kube-proxy - Thủ công Tải xuống tệp nhị phân kube-proxy từ trang phát hành Kubernetes tại đây. Ví dụ: Để tải về kube-proxy v1.13.0, chạy lệnh dưới đây. $ wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy Giải nén và chạy nó như một dịch vụ. Xem các tùy chọn kube-proxy - kubeadm Nếu bạn thiết lập nó với công cụ kubeadm, công cụ kubeadm sẽ triển khai kube-proxy dưới dạng pod trong không gian tên kube-system. Thực tế, nó được triển khai dưới dạng một daemonset trên node chủ. $ kubectl get pods -n kube-system Đó là một phần quan trọng trong việc quản lý cụm Kubernetes và đảm bảo sự kết nối mạng chính xác giữa các pod trong cụm.\nTham khảo https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/ https://kubernetes.io/docs/concepts/overview/components/ "
},
{
	"uri": "//localhost:1313/vi/1-introduce/1.9-pods/",
	"title": "Pods",
	"tags": [],
	"description": "",
	"content": "Trong hệ thống Kubernetes, Pods là một khái niệm quan trọng. Kubernetes không triển khai trực tiếp các container lên node làm việc (worker node). Thay vào đó, Kubernetes sử dụng Pods để quản lý các container.\nMỗi Pod trong Kubernetes đều chứa một hoặc nhiều container, nhưng thông thường chúng chứa một container đơn, và đó là thể hiện của ứng dụng bạn đang chạy. Pod sẽ có mối quan hệ một-một với các container chạy ứng dụng của bạn.\nPod Đa-Container Một Pod có thể chứa nhiều container, mặc dù thường không phải là nhiều container cùng một loại.\nCách triển khai Pods? Bây giờ, hãy xem cách tạo một Pod nginx sử dụng kubectl.\nĐể triển khai một container Docker bằng cách tạo một Pod, bạn có thể sử dụng lệnh sau:\n$ kubectl run nginx --image nginx Để lấy danh sách các Pods, bạn có thể sử dụng lệnh:\n$ kubectl get pods Tài liệu tham khảo Kubernetes: Kubernetes - Pod Kubernetes - Pod Overview Kubernetes - Explore Introduction "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]